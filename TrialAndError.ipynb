{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Grounds - Fit Loop\n",
    "Creating a library that helps with the pytorch looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1522,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T03:05:16.322353Z",
     "start_time": "2020-05-09T03:05:15.944994Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from uuid import uuid4\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from tqdm.autonotebook import tqdm\n",
    "from typing import Union, List, Callable, Optional, Any, Dict, Tuple\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LoopState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:15:06.168116Z",
     "start_time": "2020-05-08T16:15:06.138783Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LoopState:\n",
    "    \"\"\"\n",
    "    Maintains train/valid/test loop state for a single run of \n",
    "    a certain number of epochs, does not used to preserve state \n",
    "    between runs.\n",
    "    \"\"\"\n",
    "    _stages = ['batch','epoch_start','epoch_end']\n",
    "    _batch_step, _epoch_start, _epoch_end = _stages\n",
    "    def __init__(self, phase:str, floop:FitLoop, no_cast:bool, \n",
    "                 no_float:bool, is_train:bool, is_test:bool,\n",
    "                 dl:DataLoader\n",
    "                ):\n",
    "        \"\"\"\n",
    "        phase : phase name 'train', 'valid' or 'test'\n",
    "        floop : the calling FitLoop object\n",
    "        \"\"\"\n",
    "        self.__batch = ()\n",
    "        self.__floop = floop\n",
    "        self._no_cast = no_cast\n",
    "        self._no_float = no_float\n",
    "        self.phase = phase\n",
    "        self.batch_num = 0\n",
    "        self.epoch_num = 0\n",
    "        self.metrics = {s:{} for s in self._stages}\n",
    "        self.is_train = is_train\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # For easy access\n",
    "        bs = dl.batch_size\n",
    "        dr = dl.drop_last\n",
    "        sz = len(dl.dataset)\n",
    "        bt = sz / bs\n",
    "        \n",
    "        # Gives dataset size and batch count\n",
    "        self.size = sz\n",
    "        self.batches = math.floor(bt) if dr else math.ceil(bt)\n",
    "        self.batch_size = 0\n",
    "    \n",
    "    def __getattr__(self, name:str) -> Any:\n",
    "        # To get attributes from the FitLoop object \n",
    "        # for use in the stage functions.\n",
    "        return getattr(self.__floop, name)\n",
    "    \n",
    "    def __getitem__(self, metric_name:str):\n",
    "        # To get the metrics stored in the batch step stage\n",
    "        metric_value = self.metrics[self._batch_step][metric_name]\n",
    "        try:\n",
    "            return torch.tensor(metric_value).float()\n",
    "        except:\n",
    "            return metric_value\n",
    "    \n",
    "    \"\"\"\n",
    "    Getter and setter for the current batch\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def batch(self) -> Tuple[Tensor,...]:\n",
    "        if self._no_cast:\n",
    "            return self.__batch\n",
    "        \n",
    "        return (\n",
    "            d.to(device=self.device,dtype=self.dtype) \n",
    "            if d.is_floating_point() \n",
    "            else d.to(device=self.device,dtype=torch.long) \n",
    "            for d in self.__batch\n",
    "        )\n",
    "    \n",
    "    @batch.setter\n",
    "    def batch(self, current_batch:Tuple[Tensor,...]) -> None:\n",
    "        self.__batch = current_batch\n",
    "        \n",
    "    \"\"\"\n",
    "    Functions to append rdict values to self.metrics\n",
    "    \"\"\"\n",
    "    def _append(self, rdict:Dict[str, float], stage:str) -> None:\n",
    "        #  Append metrics to the specific stage.\n",
    "        if rdict is None:\n",
    "            if stage == self._epoch_end:\n",
    "                print(f\"no rdict returned from: f{self.phase}_{stage}\")\n",
    "            \"\"\"\n",
    "            TODO: Add warning if rdict of stage is None\n",
    "            \"\"\"\n",
    "            return\n",
    "        \n",
    "        for key in rdict:\n",
    "            if key not in self.metrics[stage]:\n",
    "                self.metrics[stage][key] = []\n",
    "            self.metrics[stage][key].append(rdict[key])\n",
    "            \n",
    "    def _append_batch_step(self, rdict:Dict[str, float]) -> None:\n",
    "        # Called after batch step rdict is returned\n",
    "        self._append(rdict, self._batch_step)\n",
    "        \n",
    "    def _append_epoch_start(self, rdict:Dict[str, float]) -> None:\n",
    "        # Called before epoch start\n",
    "        self._append(rdict, self._epoch_start)\n",
    "        \n",
    "    def _append_epoch_end(self, rdict:Dict[str, float]) -> None:\n",
    "        # Called after epoch end step rdict is returned\n",
    "        self._append(rdict, self._epoch_end)\n",
    "    \n",
    "        \n",
    "    \"\"\"\n",
    "    Functions to clear rdict values from self.metrics\n",
    "    \"\"\"\n",
    "    def _clear(self, stage:str) -> None:\n",
    "        # Clear the batch metrics at the end of the batch.\n",
    "        for mlist in self.metrics[stage]:\n",
    "            self.metrics[stage][mlist].clear()\n",
    "            \n",
    "    def _clear_batch_step(self) -> None:\n",
    "        # Called before epoch start\n",
    "        self._clear(self._batch_step)\n",
    "        \n",
    "    def _clear_epoch_start(self) -> None:\n",
    "        # Called ??\n",
    "        self._clear(self._epoch_start)\n",
    "        \n",
    "    def _clear_epoch_end(self) -> None:\n",
    "        # Called after loop end\n",
    "        self._clear(self._epoch_end)\n",
    "    \n",
    "    \"\"\"\n",
    "    State updates before epoch start and batch step stages\n",
    "    \"\"\"\n",
    "    def _pre_epoch_start_update(self, epoch_num:int) -> None:\n",
    "        self._clear_batch_step()\n",
    "        self.batch_num = 0\n",
    "        self.epoch_num = epoch_num\n",
    "    \n",
    "    def _pre_batch_step_update(self, current_batch):\n",
    "        self.batch_size = current_batch[0].size(0)\n",
    "        self.batch_num += 1\n",
    "        self.batch = current_batch\n",
    "    \n",
    "    \"\"\"\n",
    "    Functions to get various metrics at different stages \n",
    "    \"\"\"\n",
    "    def _get_epoch_metric(self, criteria:str) -> float:\n",
    "        # Last added metric that is to be used as a model \n",
    "        # selection criteria\n",
    "        metric = self.metrics[self._epoch_end][criteria][-1]\n",
    "        if self._no_float:\n",
    "            return metric\n",
    "        else:\n",
    "            return float(metric)\n",
    "    \n",
    "    def _get_epoch_metrics(self, \n",
    "                display_metrics:Optional[Union[str,List[str]]]=None\n",
    "                ) -> Dict[str,float]:\n",
    "        # Return the last saved epoch metrics\n",
    "        if isinstance(display_metrics, str):\n",
    "            return {display_metricss:self._get_epoch_metric(display_metrics)}\n",
    "        elif isinstance(display_metrics, list):\n",
    "            return {\n",
    "                metric:self._get_epoch_metric(metric)\n",
    "                for metric in display_metrics\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                metric: self._get_epoch_metric(metric)\n",
    "                for metric in self.metrics[self._epoch_end]\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FitLoopDefaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1481,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T02:54:52.802386Z",
     "start_time": "2020-05-09T02:54:52.784537Z"
    }
   },
   "outputs": [],
   "source": [
    "class FitLoopDefaults:\n",
    "    \"\"\"\n",
    "    Some default functions to be used with FitLoop,\n",
    "    allows fit loop to work without having to define \n",
    "    anything.\n",
    "    \n",
    "    Doesn't use any lr_schedulers and just a single optimizer\n",
    "    \"\"\"\n",
    "    batch_step_criteria = \"running_correct\"\n",
    "    batch_step_loss = \"running_loss\"\n",
    "    criteria = \"accuracy\"\n",
    "    loss = \"loss\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Section 1. BATCH STEP FUNCTIONS\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def _common_batch_step(state: LoopState) -> Dict[str, float]:\n",
    "        X, y = state.batch\n",
    "        y_ = state.model(X)\n",
    "        loss = state.loss_function(y_, y)\n",
    "\n",
    "        return loss, {\n",
    "            FitLoopDefaults.batch_step_criteria:\n",
    "            (y_.argmax(dim=1) == y).sum().float().item(),\n",
    "            FitLoopDefaults.batch_step_loss: (loss.item() * state.batch_size)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def train_step(state: LoopState) -> Dict[str, float]:\n",
    "        loss, rdict = FitLoopDefaults._common_batch_step(state)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return rdict\n",
    "\n",
    "    @staticmethod\n",
    "    def valid_step(state: LoopState) -> Dict[str, float]:\n",
    "        _, rdict = FitLoopDefaults._common_batch_step(state)\n",
    "        return rdict\n",
    "\n",
    "    @staticmethod\n",
    "    def test_step(state: LoopState) -> Dict[str, float]:\n",
    "        _, rdict = FitLoopDefaults._common_batch_step(state)\n",
    "        return rdict\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Section 2. EPOCH END STEPS FUNCTIONS\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def _common_epoch_end(state: LoopState) -> Dict[str, float]:\n",
    "        return {\n",
    "            FitLoopDefaults.criteria: state[FitLoopDefaults.batch_step_criteria]\\\n",
    "                .sum().float().item() / state.size,\n",
    "            FitLoopDefaults.loss:state[FitLoopDefaults.batch_step_loss]\\\n",
    "                .sum().float().item() / state.size\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def train_epoch_end(state: LoopState) -> Dict[str, float]:\n",
    "        return FitLoopDefaults._common_epoch_end(state)\n",
    "\n",
    "    @staticmethod\n",
    "    def valid_epoch_end(state: LoopState) -> Dict[str, float]:\n",
    "        return FitLoopDefaults._common_epoch_end(state)\n",
    "\n",
    "    @staticmethod\n",
    "    def test_epoch_end(state: LoopState) -> Dict[str, float]:\n",
    "        return FitLoopDefaults._common_epoch_end(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric calls\n",
    "\n",
    "```python\n",
    "# Value access\n",
    "Fitloop.metrics.train['loss']          # returns all losses from epoch end\n",
    "Fitloop.metrics.train.end['loss']      # returns all losses from epoch end\n",
    "Fitloop.metrics.train.start['loss']    # returns all losses from epoch start\n",
    "Fitloop.metrics.train.batch['loss']    # returns all losses from batch step\n",
    " \n",
    "Fitloop.metrics.train['loss'][0]       # returns losses for run 0 from epoch end\n",
    "Fitloop.metrics.valid.batch['accu'][3] # returns all validation accuracies for batch step from run 3\n",
    " \n",
    "# Value visualization \n",
    "Fitloop.metrics.plot()                 # plots validation criteria against training criteria (eg accuracy)\n",
    "                                       # if criteria not available, then first key from rdict.\n",
    "Fitloop.metrics.train.plot()           # if loss then loss else, plots first value from rdict\n",
    "Fitloop.metrics.train.plot('loss')     # plots loss \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics/MetricsAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:31:15.437676Z",
     "start_time": "2020-05-09T05:31:15.400748Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run = 0\n",
    "metric = 'loss'\n",
    "\n",
    "FitLoop.metrics.valid.start[metric:dict][run:array] -> float\n",
    "----\n",
    "FitLoop.metrics.valid.start[metric][run]\n",
    "MetricsAggregator.valid.start[metric][run]\n",
    "Metrics.start[metric][run]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Metrics:\n",
    "    \"\"\"\n",
    "    Class to keep track of metrics for a single phase.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, is_train, no_float):\n",
    "        self.stages = []\n",
    "        self._name = name\n",
    "        self._runs = 0\n",
    "        self._in_run = False\n",
    "        self._is_train = is_train\n",
    "        self._no_float = no_float\n",
    "        \n",
    "    def __repr__(self):\n",
    "        stages = ', '.join(self.stages)\n",
    "        return f\"<Metrics({self._name}) :: stages:[{stages}] at {hex(id(self))}>\"\n",
    "    \n",
    "    def _complete_run(self, is_train):\n",
    "        \"\"\"\n",
    "        Set appropriate flags.\n",
    "        Convert values for the run to numpy arrays.\n",
    "        \"\"\"\n",
    "        if not is_train == self._is_train:\n",
    "            return\n",
    "        \n",
    "        self._in_run = False\n",
    "        for stage in self.stages:\n",
    "            self_stage = getattr(self, stage)\n",
    "            for metric in self_stage:\n",
    "                m_run = self_stage[metric][self._runs - 1]\n",
    "                try:\n",
    "                    self_stage[metric][self._runs - 1] = np.array(m_run)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    def _append(self, stage, rdict):\n",
    "        \"\"\"\n",
    "        Add values in rdict to this object.\n",
    "        Metrics.stage[name:str][run:int] -> value:float\n",
    "        \"\"\"\n",
    "        if not self._in_run:\n",
    "            # Set run flag and value\n",
    "            self._in_run = True\n",
    "            self._runs += 1\n",
    "            \n",
    "        if not hasattr(self, stage):\n",
    "            self.stages.append(stage)\n",
    "            setattr(self, stage, {})\n",
    "            \n",
    "        self_stage = getattr(self, stage)\n",
    "        \n",
    "        for key in rdict:\n",
    "            val = rdict[key]\n",
    "            if key not in self_stage:\n",
    "                self_stage[key] = []\n",
    "                \n",
    "            if len(self_stage[key]) < self._runs:\n",
    "                self_stage[key].append([])\n",
    "                \n",
    "            if not self._no_float:\n",
    "                try:\n",
    "                    val = float(val)\n",
    "                except:\n",
    "                    pass\n",
    "            self_stage[key][self._runs - 1].append(val)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Clears all recorded metrics for this phase.\n",
    "        \"\"\"\n",
    "        for stage in self.stages:\n",
    "            getattr(self, stage).clear()\n",
    "        self._runs = 0\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        stages = ['epoch_end','batch_step','epoch_start']\n",
    "        for stage in stages:\n",
    "            if stage not in self.stages:\n",
    "                continue\n",
    "            if item in getattr(self, stage):\n",
    "                return getattr(self, stage)[item]\n",
    "        else:\n",
    "            raise KeyError(f\"{item} not found\")\n",
    "            \n",
    "    def _plot(self, name, metric, run_number, *args, **kwargs):\n",
    "        if run_number is None:\n",
    "            m = metric[-1]\n",
    "        elif run_number is 'all':\n",
    "            m = np.concatenate(metric)\n",
    "        elif isinstance(run_number,int):\n",
    "            m = metric[run_number]\n",
    "        else:\n",
    "            raise TypeError(\"invalid run_number\")\n",
    "        \n",
    "        plt.plot(np.arange(len(m)),m,*args,**kwargs)\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel(name)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot(self, metric:str,run_number:Optional[Union[int,str]]=None, stage:Optional[str]=None,  \n",
    "             *args, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Plots metric against iteration count for\n",
    "        all phases ['train','valid'] available if the \n",
    "        iteration count matches, else it plots metric for 'train'\n",
    "        \n",
    "        To plot individual metrics use `FitLoop.M.phase.plot`\n",
    "        To plot test metrics use `FitLoop.M.test.plot`\n",
    "        \n",
    "        phase = ['train','valid','test']\n",
    "        check FitLoop.M.[phase].stages to check stages available.\n",
    "        stages = ['epoch_end','batch_step','epoch_start']\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - metric : name of the metric that has to be plotted. eg: \"running_loss\"\n",
    "         - run_number : metric of which run to be plotted.\n",
    "             'all' -  metrics of all runs are plotted.\n",
    "             n (int) - metrics of the nth run are plotted.\n",
    "             None -  (default) the last run's metrics are plotted.\n",
    "         - stage : metric from which stage to plot, \n",
    "             if None (default) metrics are checked in all stages in the \n",
    "             above order.\n",
    "         - *args : agrs to pass to plt.plot\n",
    "         - **kwargs : kwargs to pass to plt.plot\n",
    "            \n",
    "        \"\"\"\n",
    "        if stage is not None:\n",
    "            if stage not in self.stages:\n",
    "                raise ValueError(f'invalid stage: {stage}, choose from: {self.stages}')\n",
    "            else:\n",
    "                m = getattr(self, stage)[metric]\n",
    "                self._plot(metric, m, run_number, *args,**kwargs)\n",
    "        else:\n",
    "            m = self[metric]\n",
    "            self._plot(metric, m, run_number, *args, **kwargs)\n",
    "    \n",
    "class MetricsAggregator:\n",
    "    \"\"\"\n",
    "    Class to keep track of metrics for all phases.\n",
    "    \"\"\"\n",
    "    _sets = ['train','valid','test'] # DONT CHANGE THESE, A LOT MAY BREAK\n",
    "    _TR, _VA, _TE = _sets\n",
    "    def __init__(self):\n",
    "        self.train_runs = 0\n",
    "        self.test_runs = 0\n",
    "        self._in_test = False\n",
    "        self._in_train = False\n",
    "        self._is_checkup = False\n",
    "        self._no_float = None\n",
    "        self.phases = []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<MetricsAggregator :: train_runs:{self.train_runs} test_runs:{self.test_runs} at {hex(id(self))}>\"\n",
    "    \n",
    "    def _start_run(self, is_checkup:bool, is_test:bool, no_float:bool) -> None:\n",
    "        \"\"\"\n",
    "        Set flags and run counters.\n",
    "        \"\"\"\n",
    "        if is_checkup:\n",
    "            self._is_checkup = True\n",
    "            return\n",
    "        \n",
    "        self._no_float = no_float\n",
    "        if is_test:\n",
    "            self._in_test = True\n",
    "            self.test_runs += 1\n",
    "        else:\n",
    "            self._in_train = True\n",
    "            self.train_runs += 1\n",
    "    \n",
    "    def _complete_run(self, is_checkup:bool, is_test:bool) -> None:\n",
    "        \"\"\"\n",
    "        Set flags and run counters for self and\n",
    "        attached Metrics objects\n",
    "        \"\"\"\n",
    "        if is_checkup:\n",
    "            self._is_checkup = False\n",
    "            return\n",
    "        for phase in self.phases:\n",
    "            getattr(self, phase)._complete_run(self._in_train)\n",
    "            \n",
    "        if is_test:\n",
    "            self._in_test = False\n",
    "        else:\n",
    "            self._in_train = False\n",
    "        \n",
    "    def _append(self, phase:str, stage:str, rdict:Dict[str,Union[Tensor, float, Any]]) -> None:\n",
    "        \"\"\"\n",
    "        Create a Metrics object for each phase and attach\n",
    "        it to self if not present.\n",
    "        \n",
    "        ._append rdict values to a stage in each of the \n",
    "        metrics object.\n",
    "        \"\"\"\n",
    "        if self._is_checkup:\n",
    "            return\n",
    "        \n",
    "        if not hasattr(self, phase):\n",
    "            self.phases.append(phase)\n",
    "            setattr(self, phase, Metrics(phase, self._in_train,self._no_float))\n",
    "        if self._in_train:\n",
    "            getattr(self, phase)._append(stage, rdict)\n",
    "        elif self._in_test:\n",
    "            getattr(self, phase)._append(stage, rdict)\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"\n",
    "        Clears recorded metrics for all phases.\n",
    "        \"\"\"\n",
    "        for phase in self.phases:\n",
    "            getattr(self, phase).clear()\n",
    "        self.test_runs = 0\n",
    "        self.train_runs = 0\n",
    "    \n",
    "    def plot(self, metric:str, run_number:Optional[Union[int,str]]=None, *args, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Plots metric against iteration count for\n",
    "        all phases ['train','valid'] available if the \n",
    "        iteration count matches, else it plots metric for 'train'\n",
    "        \n",
    "        To plot individual metrics use `FitLoop.M.phase.plot`\n",
    "        To plot test metrics use `FitLoop.M.test.plot`\n",
    "        \n",
    "        phase = ['train','valid','test']\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - metric : name of the metric that has to be plotted. eg: \"running_loss\"\n",
    "         - run_number : metric of which run to be plotted.\n",
    "             'all' -  metrics of all runs are plotted.\n",
    "             n (int) - metrics of the nth run are plotted.\n",
    "             None -  (default) the last run's metrics are plotted.\n",
    "         - *args : agrs to pass to plt.plot\n",
    "         - **kwargs : kwargs to pass to plt.plot\n",
    "            \n",
    "        \"\"\"\n",
    "        m = {}\n",
    "        for phase in self.phases:\n",
    "            if phase == self._TE:\n",
    "                continue\n",
    "            try:\n",
    "                ph_metric = getattr(self,phase)[metric]\n",
    "            except:\n",
    "                continue\n",
    "            if run_number is None:\n",
    "                m[phase] = ph_metric[-1]\n",
    "            elif run_number is 'all':\n",
    "                m[phase] = np.concatenate(ph_metric)\n",
    "            elif isinstance(run_number,int):\n",
    "                m[phase] = ph_metric[run_number]\n",
    "            else:\n",
    "                raise TypeError(\"invalid run_number\")\n",
    "            \n",
    "        # Plot both train and valid if the lengths match, else only Train\n",
    "        if self._TR in m and self._VA in m:\n",
    "            tr_l = len(m[self._TR])\n",
    "            va_l = len(m[self._VA])\n",
    "            if tr_l == va_l:\n",
    "                plt.plot(np.arange(tr_l),m[self._TR], label=self._TR,*args,**kwargs)\n",
    "                plt.plot(np.arange(va_l),m[self._VA], label=self._VA,*args,**kwargs)\n",
    "            else:\n",
    "                plt.plot(np.arange(tr_l),m[self._TR], label=self._TR,*args,**kwargs)\n",
    "        elif self._TR in m and self._VA not in m:\n",
    "            tr_l = len(m[self._TR])\n",
    "            plt.plot(np.arange(tr_l),m[self._TR], label=self._TR,*args,**kwargs)\n",
    "        elif self._VA in m and self._TR not in m:\n",
    "            va_l = len(m[self._VA])\n",
    "            plt.plot(np.arange(va_l),m[self._VA], label=self._VA,*args,**kwargs)\n",
    "        else:\n",
    "            print(\"no values to plot\")\n",
    "            return\n",
    "\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FitLoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1482,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T02:55:00.961181Z",
     "start_time": "2020-05-09T02:55:00.953295Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def ftime(t1:float,t2:float)->str:\n",
    "    t = t2-t1\n",
    "    gm = time.gmtime(t)\n",
    "    try:\n",
    "        ms = str(t).split('.')[1][:3]\n",
    "    except:\n",
    "        ms = \"\"\n",
    "    if gm.tm_hour > 0:\n",
    "        fstr = \"%H h %M m %S s\"\n",
    "    elif gm.tm_min > 0:\n",
    "        fstr = \"%M m %S s\"\n",
    "    else:\n",
    "        fstr = \"%S s\"\n",
    "    return time.strftime(fstr, gm) + f\" {ms} ms\"\n",
    "\n",
    "def ptime(t:float)->str:\n",
    "    gm = time.gmtime(t)\n",
    "    try:\n",
    "        fs = str(t).split('.')[1]\n",
    "        ms = fs[:3]\n",
    "        us = fs[3:6]\n",
    "    except:\n",
    "        ms = \"\"\n",
    "    if gm.tm_hour > 0:\n",
    "        fstr = \"%H h %M m %S s\"\n",
    "    elif gm.tm_min > 0:\n",
    "        fstr = \"%M m %S s\"\n",
    "    else:\n",
    "        fstr = \"%S s\"\n",
    "    return time.strftime(fstr, gm) + f\" {ms} ms {us} us\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1764,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:43:18.140752Z",
     "start_time": "2020-05-09T05:43:18.021032Z"
    }
   },
   "outputs": [],
   "source": [
    "class FitLoop:\n",
    "    \"\"\"\n",
    "    FitLoop trains Pytorch models.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 0 \n",
    "    \n",
    "    Initialization\n",
    "    \"\"\"\n",
    "    _sets = ['train','valid','test'] # DONT CHANGE THESE, A LOT MAY BREAK\n",
    "    _TR, _VA, _TE = _sets\n",
    "    \n",
    "    _model_type = ['pretrained','best']\n",
    "    _PR, _BS = _model_type\n",
    "    def __init__(self, \n",
    "                 # Basic Blocks\n",
    "                 model: Module, \n",
    "                 optimizer: Union[Optimizer,List[Optimizer]], \n",
    "                 loss_function: Callable[[Tensor,Tensor],Tensor], \n",
    "                 \n",
    "                 # DataLoader\n",
    "                 train_dl: Optional[DataLoader]=None, \n",
    "                 valid_dl: Optional[DataLoader]=None, \n",
    "                 test_dl: Optional[DataLoader]=None, \n",
    "                 \n",
    "                 # Batch Step\n",
    "                 train_step: Callable[[LoopState],Dict[str, Any]]=FitLoopDefaults.train_step,\n",
    "                 valid_step: Optional[Callable[[LoopState],Dict[str, Any]]]=FitLoopDefaults.valid_step,\n",
    "                 test_step: Optional[Callable[[LoopState],Dict[str, Any]]]=FitLoopDefaults.test_step,\n",
    "                 \n",
    "                 # Epoch Start Step\n",
    "                 train_epoch_start: Optional[Callable[[LoopState],Dict[str, Any]]]=None,\n",
    "                 valid_epoch_start: Optional[Callable[[LoopState],Dict[str, Any]]]=None,\n",
    "                 test_epoch_start: Optional[Callable[[LoopState],Dict[str, Any]]]=None,\n",
    "                 \n",
    "                 # Epoch End Step\n",
    "                 train_epoch_end: Callable[[LoopState],Dict[str, Any]]=FitLoopDefaults.train_epoch_end,\n",
    "                 valid_epoch_end: Optional[Callable[[LoopState],Dict[str, Any]]]=FitLoopDefaults.valid_epoch_end,\n",
    "                 test_epoch_end: Optional[Callable[[LoopState],Dict[str, Any]]]=FitLoopDefaults.test_epoch_end,\n",
    "                 \n",
    "                 # Other Stage Functions\n",
    "                 preloop: Optional[Callable[[dict],None]]=None,\n",
    "                 postloop: Optional[Callable[[dict],None]]=None,\n",
    "                 \n",
    "                 # Other Args\n",
    "                 lr_scheduler: Optional[Union[_LRScheduler, Any, List[Union[_LRScheduler,Any]]]]=None,\n",
    "                 device: torch.device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'), \n",
    "                 configure_optimizer:Callable[[FitLoop],None]=None,\n",
    "                 dtype: torch.dtype=torch.float32,\n",
    "                 \n",
    "                 # Model Evaluation\n",
    "                 criteria: Optional[str]=None,\n",
    "                 criteria_direction: int=1,\n",
    "                 \n",
    "                 # Preserving Model State\n",
    "                 save_to_disk: bool=False,\n",
    "                 save_path: str=\"models\",\n",
    "                 pretrained_model_name: Optional[str]=None,\n",
    "                 best_model_name: Optional[str]=None,\n",
    "                ) -> None:\n",
    "        \"\"\"\n",
    "        FitLoop constructor\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "        # Basic Blocks\n",
    "            The bare minimum required along with train_dl.\n",
    "            - model : nn.Module model that has to be trained\n",
    "            - optimizer : an optimizer from torch.optim\n",
    "            - loss_function : function to compute loss\n",
    "         \n",
    "        # DataLoader\n",
    "            - train_dl : training DataLoader\n",
    "            - valid_dl : validation DataLoader, if None validation will be ignored\n",
    "            - test_dl : testing DataLoader, if None `.test()` will not run\n",
    "         \n",
    "        # Batch Step\n",
    "            Functions that take in a LoopState object to perform \n",
    "            required calculations, functions should return a dict with values\n",
    "            to be used in the epoch end step.\n",
    "            - train_step : portion of the loop where forward and backward \n",
    "                passes take place.\n",
    "            - valid_step : validation portion of the loop.\n",
    "            - test_step : called when `FitLoop.test()` is called.\n",
    "        \n",
    "        # Epoch Start Step\n",
    "            - train_epoch_start : Train phase stage function in the epoch loop at the start.\n",
    "            - valid_epoch_start : Valid phase stage function in the epoch loop at the start.\n",
    "            - test_epoch_start : Test phase stage function in the epoch loop at the start.\n",
    "        \n",
    "        # Epoch End Step\n",
    "            Functions that take in a LoopState object to perform \n",
    "            required calculations, functions should return a dict with values\n",
    "            that are to be returned when the loop is over.\n",
    "            - train_epoch_end : after training epoch has ended.\n",
    "            - valid_epoch_end : after validation epoch has ended.\n",
    "            - test_epoch_end : called when the test loop is done, one iteration\n",
    "                over all batches in the test dataloader.\n",
    "                \n",
    "        # Other Stage Functions\n",
    "            - preloop : function that is called before the epoch loop runs, it is passed\n",
    "                all the loop variables (local()) in a dict.\n",
    "            - postloop : function that is called after the epoch loop runs, it is passed\n",
    "                all the loop variables (local()) in a dict.\n",
    "        \n",
    "        # Other Args\n",
    "            - lr_scheduler : scheduler from torch.optim.lr_scheduler\n",
    "            - device : torch.device model will be cast to device this prior to the loop\n",
    "            - configure_optimizer : function that configures the optimizer, will be called\n",
    "                whenever the model weights have to be restored.\n",
    "            - dtype : floating point dtype to cast model and data to\n",
    "            \n",
    "        # Model Evaluation\n",
    "            - criteria : model evaluation metric that is returned in the dict of the\n",
    "                `valid_epoch_end` stage function if None (default) best model and \n",
    "                best score are not tracked.\n",
    "            - criteria_direction : whether more is better (1) or less is better (-1) \n",
    "                for model score criteria.\n",
    "        \n",
    "        # Preserving Model State\n",
    "            - save_to_disk : True then save pretrained and best_model to the disk, else it is \n",
    "                stored as an attribute.\n",
    "            - save_path : location where the initial and pretrained models are to be saved\n",
    "            - pretrained_model_name : Name to save the pretrained model by\n",
    "            - best_model_name : Name to save the best model by\n",
    "        \"\"\"\n",
    "        # Basic Blocks\n",
    "        self._model = None # Setter called below\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "        # DataLoaders\n",
    "        self.train_dl = train_dl\n",
    "        self.valid_dl = valid_dl\n",
    "        self.test_dl = test_dl\n",
    "        \n",
    "        # Batch Step\n",
    "        self.train_step = train_step\n",
    "        self.valid_step = valid_step\n",
    "        self.test_step = test_step\n",
    "        \n",
    "        # Epoch Start Step\n",
    "        self.train_epoch_start = train_epoch_start\n",
    "        self.valid_epoch_start = valid_epoch_start\n",
    "        self.test_epoch_start = test_epoch_start\n",
    "        \n",
    "        # Epoch End Step\n",
    "        self.train_epoch_end = train_epoch_end\n",
    "        self.valid_epoch_end = valid_epoch_end\n",
    "        self.test_epoch_end = test_epoch_end\n",
    "        \n",
    "        # Other Stage Functions\n",
    "        self.preloop = preloop\n",
    "        self.postloop = postloop\n",
    "        \n",
    "        # Other Args\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.device = device\n",
    "        self.configure_optimizer = configure_optimizer\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        # Model Evaluation\n",
    "        self.criteria = criteria\n",
    "        self.criteria_direction = criteria_direction\n",
    "        \n",
    "        \n",
    "        # Preserving Model State\n",
    "        if pretrained_model_name is None:\n",
    "            u = str(uuid4()).split('-')[1]\n",
    "            pretrained_model_name = f\"pretrained_{u}.pt\"\n",
    "        if best_model_name is None:\n",
    "            u = str(uuid4()).split('-')[1]\n",
    "            best_model_name = f\"best_{u}.pt\"\n",
    "        self.pretrained_model_name = pretrained_model_name\n",
    "        self.best_model_name = best_model_name\n",
    "        self.save_to_disk = save_to_disk\n",
    "        self.save_path = Path(save_path)\n",
    "        \n",
    "        # INITIALIZE NON ARGS\n",
    "        self.best_model_state_dict = None\n",
    "        self.pretrained_model_state_dict = None\n",
    "        self.epoch_num = 0\n",
    "        self.best_score = self.criteria_direction * float('-inf')\n",
    "        self.time_profile = {}\n",
    "        self.metrics = MetricsAggregator()\n",
    "        \n",
    "        # Change criteria if defaults are being used\n",
    "        if self.valid_step is FitLoopDefaults.valid_step:\n",
    "            self.criteria = FitLoopDefaults.criteria\n",
    "            \n",
    "        # Basic Blocks - Calling model setter\n",
    "        self.model = model\n",
    "    \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self._model = model.to(device=self.device, dtype=self.dtype)\n",
    "        self.__save_model(self._PR)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.criteria is not None:\n",
    "            cri = f\"{self.criteria}:{self.best_score:0.4f}\"\n",
    "        else:\n",
    "            cri = f\"best_score:{self.best_score}\"\n",
    "        return f\"<FitLoop :: epoch_num:{self.epoch_num} {cri} at {hex(id(self))}>\"\n",
    "        \n",
    "            \n",
    "            \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 1\n",
    "    \n",
    "    Helper functions used in `__loop`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call_batch_step(self, state:LoopState, track_batch_metrics:bool) -> None:\n",
    "        phase = state.phase\n",
    "        step_funcs = [self.train_step, self.valid_step, self.test_step]\n",
    "        step_funcs = {s:f for s,f in zip(self._sets, step_funcs)}\n",
    "        step_func = step_funcs[phase]\n",
    "        \n",
    "        if step_func is None:\n",
    "            raise AttributeError(f\"{phase}_step not assigned\")\n",
    "        rdict = step_func(state)\n",
    "        if isinstance(rdict,dict):\n",
    "            state._append_batch_step(rdict)\n",
    "            if track_batch_metrics:\n",
    "                self.metrics._append(phase,'batch_step',rdict)\n",
    "        \n",
    "    def __call_epoch_start_step(self, state:LoopState) -> None:\n",
    "        phase = state.phase\n",
    "        step_funcs = [self.train_epoch_start,self.valid_epoch_start,self.test_epoch_start]\n",
    "        step_funcs = {s:f for s,f in zip(self._sets, step_funcs)}\n",
    "        step_func = step_funcs[phase]\n",
    "        \n",
    "        if step_func is None:\n",
    "            return None\n",
    "        rdict = step_func(state)\n",
    "        if isinstance(rdict,dict):\n",
    "            state._append_epoch_start(rdict)\n",
    "            self.metrics._append(phase,'epoch_start',rdict)\n",
    "        \n",
    "    def __call_epoch_end_step(self, state:LoopState) -> None:\n",
    "        phase = state.phase\n",
    "        step_funcs = [self.train_epoch_end,self.valid_epoch_end,self.test_epoch_end]\n",
    "        step_funcs = {s:f for s,f in zip(self._sets, step_funcs)}\n",
    "        step_func = step_funcs[state.phase]\n",
    "        \n",
    "        if step_func is None:\n",
    "            raise AttributeError(f\"{phase}_end_step not assigned\")\n",
    "        rdict = step_func(state)\n",
    "        if isinstance(rdict,dict):\n",
    "            state._append_epoch_end(rdict)\n",
    "            self.metrics._append(phase,'epoch_end',rdict)\n",
    "        \n",
    "    def __get_dl(self, is_test:bool, use_test_dl:Optional[bool]=None,\n",
    "                train_dl:Optional[DataLoader]=None,\n",
    "                valid_dl:Optional[DataLoader]=None,\n",
    "                test_dl:Optional[DataLoader]=None\n",
    "                )-> Dict[str,DataLoader]:\n",
    "        if is_test:\n",
    "            if test_dl is not None:\n",
    "                return {self._TE:test_dl}\n",
    "            \n",
    "            if use_test_dl is not None and not use_test_dl:\n",
    "                te_dl = valid_dl if valid_dl is not None else self.valid_dl\n",
    "                if te_dl is None:\n",
    "                    raise AttributeError(\"valid_dl not assigned\")\n",
    "                return {self._TE:te_dl}\n",
    "            \n",
    "            elif self.test_dl is None:\n",
    "                raise AttributeError(\"test_dl not assigned\")\n",
    "            return {self._TE:self.test_dl}\n",
    "        \n",
    "        va_dl = valid_dl if valid_dl is not None else self.valid_dl\n",
    "        tr_dl = train_dl if train_dl is not None else self.train_dl\n",
    "        \n",
    "        if tr_dl is None:\n",
    "            raise AttributeError(\"train_dl not assigned, please use the train_dl kwarg\")\n",
    "        if  va_dl is not None:\n",
    "            return {self._TR:tr_dl, self._VA:va_dl}\n",
    "        else:\n",
    "            return {self._TR:tr_dl}\n",
    "    \n",
    "    def __profile_time(self, t1, t2, name, is_test):\n",
    "        if t1 is None or t2 is None:\n",
    "            return\n",
    "        else:\n",
    "            t = t2 - t1\n",
    "            a,*b =  name.split('_')\n",
    "            if len(b) == 0:\n",
    "                a += \"_t\" if is_test else \"\"\n",
    "                if a not in self.time_profile:\n",
    "                    self.time_profile[a] = []\n",
    "                self.time_profile[a].append(t)\n",
    "            else:\n",
    "                b = '_'.join(b)\n",
    "                b += \"_t\" if is_test else \"\"\n",
    "                if a not in self.time_profile:\n",
    "                    self.time_profile[a] = {}\n",
    "                if b not in self.time_profile[a]:\n",
    "                    self.time_profile[a][b] = []\n",
    "                self.time_profile[a][b].append(t)\n",
    "                \n",
    "    def print_time_profile(self):\n",
    "        if len(self.time_profile) == 0:\n",
    "            print(\"please run FitLoop.run_profiler(print_outcome=False) first\")\n",
    "        else:\n",
    "            print(\"AVERAGE TIMES\")\n",
    "            for i,m in enumerate(self.time_profile):\n",
    "                if isinstance(self.time_profile[m], list):\n",
    "                    temp = torch.tensor(self.time_profile[m]).mean().item()\n",
    "                    prf = f\"{i+1}. {m}:\".ljust(20)\n",
    "                    print(f\"{prf} {ptime(temp)}\")\n",
    "                else:\n",
    "                    print(f\"{i+1}. {m}\")\n",
    "                    \n",
    "                    for j,n in enumerate(self.time_profile[m]):\n",
    "                        temp = torch.tensor(self.time_profile[m][n]).mean().item()\n",
    "                        prf = f\"{j+1}. {n}:\".ljust(18)\n",
    "                        print(f\"  {prf} {ptime(temp)}\")\n",
    "            \n",
    "    \n",
    "    def __profile_other(self,val,name):\n",
    "        # TODO: Profiler for other metrics: CPU, GPU, RAM usages.\n",
    "        print(\"NOT IMPLEMENTED YET\")\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 2\n",
    "    \n",
    "    The main loop function __loop \n",
    "    \"\"\"\n",
    "    \n",
    "    def __loop(self, \n",
    "            epochs:int=1,  print_every:int=1, \n",
    "            steps: Optional[int]=None, load_best:bool=False, \n",
    "            profiler:bool=False, is_test:bool=False,\n",
    "            track_batch_metrics:bool=True, define_all:bool=False,\n",
    "            continue_loop:int=0, no_print:bool=False, no_cast:bool=False,\n",
    "            display_metrics:Optional[Union[str,List[str]]]=None, no_float:bool=False,\n",
    "            no_progress:bool=False,is_sanity_check:bool=False, use_test_dl:Optional[bool]=None,\n",
    "            train_dl:Optional[DataLoader]=None,\n",
    "            valid_dl:Optional[DataLoader]=None,\n",
    "            test_dl:Optional[DataLoader]=None\n",
    "           ) -> None:\n",
    "        \"\"\"\n",
    "        Runs the training loop for `epochs`\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - epochs : should be a non negative integer\n",
    "         - print_every : if 0 will not print, else will print at given epoch\n",
    "         - steps : number of batches to run in each phase [train,valid] \n",
    "             for check if everything is working.\n",
    "         - load_best : whether to load the best model after training, works only if validation\n",
    "             parameters are defined `valid_dl`, `valid_step`, `valid_epoch_end`\n",
    "         - profiler : whether to keep track of time taken by various sections\n",
    "         - is_test : whether it is a model testing loop or training/validation loop\n",
    "         - track_batch_metrics : whether to store the values returned in the batch steps\n",
    "         - define_all : If True then `torch.set_grad_enabled`, `optimizer.zero_grad` and model mode \n",
    "             ie [train,eval] have to be called where required (usually in the `train_step` function).\n",
    "         - continue_loop : Will ask whether to continue training after `continue_loop` epochs, should\n",
    "             be a positive integer.\n",
    "         - no_print : If True will suppress all print statements, can be used when custom logging is\n",
    "             used in the stage functions.\n",
    "         - no_cast : True, if data casting has to be manually set in the stage functions\n",
    "         - display_metrics : List of metrics returned in the epoch_end stage rdict that has to be \n",
    "             displayed, if None (default) all the returned metrics are displayed.\n",
    "         - no_float : True don't apply float conversion to returned metrics.\n",
    "         - no_progress : False don't show the progress bars.\n",
    "         - is_sanity_check : For sanity check mode.\n",
    "         - use_test_dl : For use with sanity check, to use valid dl or test dl.\n",
    "         - train_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - valid_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - test_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "        \n",
    "        \"\"\"\n",
    "        time_ = lambda p : time.perf_counter() if p else None\n",
    "        tpe = lambda : time_(print_every != 0) # Returns the time \n",
    "        tpr = lambda : time_(profiler) # Times keeping used by profiler\n",
    "        \n",
    "        prof_total = tpr() # ‚è≥\n",
    "        total_time_start = tpe()\n",
    "        \n",
    "        # INITILIZING VARIABLES -----\n",
    "        is_train = not(is_test or is_sanity_check or profiler)\n",
    "        pre = self.preloop is not None\n",
    "        post = self.postloop is not None\n",
    "        self.metrics._start_run((is_sanity_check or profiler),is_test, no_float)\n",
    "        \n",
    "        # Storage\n",
    "        prof_time = {}\n",
    "        dl = self.__get_dl(is_test, use_test_dl, train_dl, valid_dl, test_dl)\n",
    "        sz = { k : len(dl[k].dataset) for k in dl }\n",
    "        phases = [ph for ph in dl]\n",
    "        state = {ph: LoopState(ph,self,no_cast,no_float,is_train, is_test, dl[ph]) for ph in phases}\n",
    "\n",
    "        # Markers\n",
    "        self.__save_model(self._BS)\n",
    "        \n",
    "        # TQDM Progressbar\n",
    "        tot_size = torch.tensor([len(dl[d]) for d in dl]).sum().long().item()\n",
    "        if steps is not None:\n",
    "            tot_size = torch.tensor([len(dl[d]) if len(dl[d]) < steps else steps for d in dl])\\\n",
    "                .sum().long().item()\n",
    "                                 \n",
    "        l_bar='{desc}: {percentage:3.0f}%|' \n",
    "        r_bar='| [ {n_fmt}/{total_fmt} ] :: [ {elapsed} < {remaining} ] :: [ {rate_fmt} ] ' \n",
    "        bar_format = f'{l_bar}'+'{bar}'+f'{r_bar}'\n",
    "        etqdm = lambda e: tqdm(range(e),desc=\"EPOCH :\", disable=no_progress or is_test, \\\n",
    "                               bar_format=bar_format, unit=\"epoch\",dynamic_ncols=True)\n",
    "        btqdm = lambda : tqdm(range(tot_size),leave=False or is_test,disable=no_progress,\\\n",
    "                               bar_format=bar_format,unit=\"batch\",dynamic_ncols=True)\n",
    "         \n",
    "        # PROFILER STATEMENT ---------\n",
    "        if profiler:\n",
    "            print(f\"RUNNING PROFILER: {'TEST' if is_test else 'TRAIN'} LOOP\" , (\"\" if is_test else f\"{epochs} EPOCH(s)\"))\n",
    "            for dlo in dl: \n",
    "                dlo_b = len(dl[dlo])\n",
    "                dlo_s = len(dl[dlo].dataset)\n",
    "                bs = dl[dlo].batch_size\n",
    "                if steps is not None and dlo_b > steps:\n",
    "                    dlo_b = steps\n",
    "                lb = dlo_s % bs\n",
    "                lb = lb if lb > 0 else bs\n",
    "                print(f\"  {dlo.ljust(5)} dl :: batches: {dlo_b:4} batch_size: {dl[dlo].batch_size:4} last_batch: {lb:4} dataset_size: {dlo_s:6}\")\n",
    "            print()\n",
    "        \n",
    "        \n",
    "        # CONVENIENCE FUNCTIONS ------\n",
    "        \n",
    "        # Function to get formatted epochs (from 1 not 0)\n",
    "        r_just_val = len(str(epochs))*2 + 3\n",
    "        estr = lambda e: f\"[{e + 1}/{epochs}]\".rjust(r_just_val)\n",
    "\n",
    "        # Function to print every `print_every` epochs.\n",
    "        def eprint(e,st):\n",
    "            if not no_print:\n",
    "                if (e == 0) and (print_every != 0):\n",
    "                    print(st,end=\"\")\n",
    "                elif (e + 1) % print_every == 0:\n",
    "                    print(st,end=\"\")\n",
    "\n",
    "        # Function for phase strings.\n",
    "        def statstr(phase, epoch_metrics, rjust=True):\n",
    "            mt = ' | '.join([f\"{m}: {epoch_metrics[m]:0.4f}\"for m in epoch_metrics])\n",
    "            st =  f\"{phase} :: {mt} \\n\"\n",
    "            if rjust:\n",
    "                return st.rjust(r_just_val + len(st) + 3)\n",
    "            else:\n",
    "                return st\n",
    "            \n",
    "        # To set is_test\n",
    "        def _profile_time(t1,t2,name):\n",
    "            self.__profile_time(t1,t2,name,is_test=is_test)\n",
    "            \n",
    "        prof_preloop = tpr()\n",
    "        pre and self.preloop(locals())\n",
    "        pre and profiler and _profile_time(prof_total_start, tpr(), 'preloop') # ‚è≥\n",
    "            \n",
    "        profiler and _profile_time(prof_total, tpr(), 'initialize') # ‚è≥\n",
    "        \n",
    "        # EPOCH LOOP - START -----------\n",
    "        prof_epoch_loop = tpr()\n",
    "        for e in etqdm(epochs):\n",
    "            prof_epoch_inner = tpr() # ‚è≥\n",
    "            epoch_time_start = tpe()\n",
    "            \n",
    "            # UPDATE: epoch_num\n",
    "            if not is_sanity_check and not profiler and not is_test:\n",
    "                self.epoch_num += 1\n",
    "            \n",
    "            # PHASE LOOP [TRAIN|VALID,TEST] - START\n",
    "            prof_phase_loop = tpr() # ‚è≥\n",
    "            prog_bar_phase = btqdm()\n",
    "            for phase in phases:\n",
    "                prof_phase_inner = tpr() # ‚è≥\n",
    "                prog_bar_phase.desc = phase.upper().ljust(5)+\" :\"\n",
    "                \n",
    "                # EPOCH START STEP - START \n",
    "                prof_epoch_start = tpr() # ‚è≥\n",
    "                self.__call_epoch_start_step(state[phase])\n",
    "                profiler and _profile_time(prof_epoch_start,tpr(),f'{phase}_epoch_start') # ‚è≥\n",
    "                # EPOCH START STEP - END \n",
    "                \n",
    "                is_tr = phase == self._TR\n",
    "                if is_tr:\n",
    "                    eprint(e,estr(e)+f\" - \")\n",
    "                \n",
    "                # UPDATE: batch_num, metrics['batch'], epoch_num\n",
    "                state[phase]._pre_epoch_start_update(e)\n",
    "                \n",
    "                \n",
    "                if not define_all:\n",
    "                    if is_tr:\n",
    "                          model.train()\n",
    "                    else:\n",
    "                          model.eval()\n",
    "                            \n",
    "                # BATCH LOOP - START \n",
    "                prof_batch_loop = tpr() # ‚è≥\n",
    "                for step, batch in enumerate(dl[phase]):\n",
    "                    prof_batch_inner = tpr() # ‚è≥\n",
    "                    \n",
    "                    if steps is not None and step == steps: break\n",
    "                    \n",
    "                    # Update LoopState: batch_num, batch and batch_size\n",
    "                    state[phase]._pre_batch_step_update(batch)\n",
    "                    \n",
    "                    # BATCH STEP - START \n",
    "                    prof_batch_step = tpr() # ‚è≥\n",
    "                    if define_all:\n",
    "                        self.__call_batch_step(state[phase], track_batch_metrics)\n",
    "                    else:\n",
    "                        if isinstance(self.optimizer,list):\n",
    "                            for opt in self.optimizer:opt.zero_grad()\n",
    "                        else:\n",
    "                            self.optimizer.zero_grad()\n",
    "                        with torch.set_grad_enabled(is_tr):\n",
    "                            self.__call_batch_step(state[phase], track_batch_metrics)\n",
    "                    profiler and _profile_time(prof_batch_step,tpr(),f'{phase}_step') # ‚è≥\n",
    "                    # BATCH STEP - END \n",
    "                    prog_bar_phase.update(1)\n",
    "                    \n",
    "                    profiler and _profile_time(prof_batch_inner,tpr(),f'{phase}_batch_inner') # ‚è≥\n",
    "                    \n",
    "                profiler and _profile_time(prof_batch_loop,tpr(),f'{phase}_batch_loop') # ‚è≥\n",
    "                # BATCH LOOP - END \n",
    "                \n",
    "                # EPOCH END STEP - START \n",
    "                prof_epoch_end = tpr()\n",
    "                self.__call_epoch_end_step(state[phase])\n",
    "                profiler and _profile_time(prof_epoch_end,tpr(),f'{phase}_epoch_end') # ‚è≥\n",
    "                # EPOCH END STEP - END \n",
    "                \n",
    "                # UPDATE MARKERS\n",
    "                if not (is_tr or is_test or profiler or is_sanity_check) and self.criteria is not None:\n",
    "                    score = state[phase]._get_epoch_metric(self.criteria)\n",
    "                    direc = self.criteria_direction > 0\n",
    "                    is_better = (score > self.best_score) if direc else (score < self.best_score)\n",
    "                    if is_better:\n",
    "                        self.best_score = score\n",
    "                        self.__save_model(self._BS)\n",
    "\n",
    "                # PRINT EPOCH[PHASE] METRICS\n",
    "                epoch_metrics = state[phase]._get_epoch_metrics(display_metrics)\n",
    "                if is_tr or is_test:\n",
    "                    eprint(e,statstr(phase, epoch_metrics,False))\n",
    "                else:\n",
    "                    eprint(e,statstr(phase, epoch_metrics))\n",
    "                    \n",
    "                profiler and _profile_time(prof_phase_inner,tpr(),f'{phase}_phase_inner') # ‚è≥\n",
    "                \n",
    "            profiler and _profile_time(prof_phase_loop,tpr(),f'phase loop') # ‚è≥\n",
    "            # PHASE LOOP [TRAIN|VALID,TEST] - END\n",
    "            \n",
    "            # PRINT EPOCH TIMES\n",
    "            epoch_time_end = tpe()\n",
    "            epoch_time = ftime(epoch_time_start, epoch_time_end)\n",
    "            epoch_time = f\"epoch time: {epoch_time}\" + (\"\\n\" if no_progress else \"\")\n",
    "            not is_test and eprint(e,epoch_time.rjust(len(epoch_time) + r_just_val + 3)+\"\\n\")\n",
    "            \n",
    "            prog_bar_phase.close()\n",
    "            # CONTINUE LOOP ?\n",
    "            if continue_loop > 0 and \\\n",
    "                not (is_sanity_check or is_test or profiler) and \\\n",
    "                ((e + 1) % continue_loop == 0) and (e + 1 != epochs):\n",
    "                cont = input(\"continue loop ([y]/n): \")\n",
    "                not no_print and print()\n",
    "                if cont == 'n':\n",
    "                    break\n",
    "            \n",
    "            profiler and _profile_time(prof_epoch_inner,tpr(),f'epoch_inner') # ‚è≥\n",
    "\n",
    "        profiler and _profile_time(prof_epoch_loop,tpr(),f'epoch_loop') # ‚è≥\n",
    "        # EPOCH LOOP - END \n",
    "        \n",
    "        prof_postloop = tpr()\n",
    "        post and self.postloop(locals())\n",
    "        post and profiler and _profile_time(prof_postloop, tpr(), 'postloop') # ‚è≥\n",
    "        \n",
    "        # PRINT FINAL METRICS\n",
    "        eprint(0,\"-\"*r_just_val)\n",
    "        total_time_end = tpe()\n",
    "        total_time = ftime(total_time_start,total_time_end)\n",
    "        eprint(0, f\"\\ntotal time: {total_time}\\n\")\n",
    "        if self.criteria is not None and not is_test and self._VA in dl:\n",
    "            eprint(0, f\"best score: {self.best_score:0.4f}\\n\")\n",
    "\n",
    "        # RESTORE BEST MODEL\n",
    "        prof_restore_model = tpr() # ‚è≥\n",
    "        if load_best or profiler or is_sanity_check:\n",
    "            self.__load_model(self._BS)\n",
    "        profiler and _profile_time(prof_restore_model,tpr(),f'restore model') # ‚è≥\n",
    "\n",
    "        self.metrics._complete_run((is_sanity_check or profiler),is_test)\n",
    "        profiler and _profile_time(prof_total,tpr(),f'total',) # ‚è≥\n",
    "        # __loop - END \n",
    "\n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 3 - A\n",
    "    \n",
    "    Loop methods for training and testing of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(self, \n",
    "            epochs:int=1, print_every:int=1,\n",
    "            display_metrics:Optional[Union[str,List[str]]]=None,\n",
    "            train_dl:Optional[DataLoader]=None,\n",
    "            valid_dl:Optional[DataLoader]=None,\n",
    "            track_batch_metrics:bool=True, load_best:bool=True,\n",
    "            continue_loop:int=0, define_all:bool=False,  \n",
    "            no_print:bool=False, no_cast:bool=False,\n",
    "            no_float:bool=False, no_progress:bool=False,\n",
    "           ) -> None:\n",
    "        \"\"\"\n",
    "        Runs the training loop for `epochs`\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - epochs : should be a non negative integer\n",
    "         - print_every : if 0 will not print, else will print at given epoch\n",
    "         - display_metrics : List of metrics returned in the epoch_end stage rdict that has to be \n",
    "             displayed, if None (default) all the returned metrics are displayed.\n",
    "         - train_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - valid_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - track_batch_metrics : whether to store the values returned in the batch steps\n",
    "         - load_best : whether to load the best model after training, works only if validation\n",
    "             parameters are defined `valid_dl`, `valid_step`, `valid_epoch_end`\n",
    "         -  continue_loop : Will ask whether to continue training after `continue` epochs; should\n",
    "             be a positive integer.\n",
    "         - define_all : If True then `torch.set_grad_enabled`, `optimizer.zero_grad` and model mode \n",
    "             ie [train,eval] have to be called where required (usually in the `train_step` function).\n",
    "         - no_print : If True will suppress all print statements, can be used when custom logging is\n",
    "             used in the stage functions.\n",
    "         - no_cast : True, if data casting has to be manually set in the stage functions\n",
    "         - no_float : True, don't apply float conversion to returned metrics.\n",
    "         - no_progress : True, don't show the progress bar.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.__loop(epochs=epochs, print_every=print_every,\n",
    "                    display_metrics=display_metrics, track_batch_metrics=track_batch_metrics,\n",
    "                    load_best=load_best, continue_loop=continue_loop, define_all=define_all,\n",
    "                    no_print=no_print, no_cast=no_cast, no_float=no_float, no_progress=no_progress,\n",
    "                    train_dl=train_dl, valid_dl=valid_dl\n",
    "                   )\n",
    "    \n",
    "    def train(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Alias for FitLoop.fit\n",
    "        \"\"\"\n",
    "        self.fit(*args, **kwargs)\n",
    "    \n",
    "    def test(self, test_dl:Optional[DataLoader]=None,\n",
    "            no_print:bool=False, no_cast:bool=False, no_float:bool=False, \n",
    "            ) -> None:\n",
    "        \"\"\"\n",
    "        For model testing. Runs loop for one epoch using test DataLoader and test stage functions.\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - test_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - no_print : If True will suppress all print statements, can be used when custom logging is\n",
    "             used in the stage functions.\n",
    "         - no_cast : True, if model and data casting has to be manually set in the stage functions\n",
    "         - no_float : True don't apply float conversion to returned metrics.\n",
    "         - no_progress : True, don't show the progress bar.\n",
    "        \"\"\"\n",
    "        self.__loop(is_test=True, no_print=no_print, no_cast=no_cast, no_float=no_float, test_dl=test_dl)\n",
    "        \n",
    "    \"\"\"\n",
    "    SECTION: 3 - B\n",
    "    \n",
    "    Loop methods for (sort of) unit testing and timing of components.\n",
    "    \"\"\"\n",
    "    def run_profiler(self,\n",
    "            epochs:Optional[int]=1, steps: Optional[int]=None, define_all:bool=False,\n",
    "            no_cast:bool=False, no_float:bool=False, no_progress:bool=False, print_outcome:bool=True,\n",
    "            train_dl:Optional[DataLoader]=None,\n",
    "            valid_dl:Optional[DataLoader]=None,\n",
    "            test_dl:Optional[DataLoader]=None\n",
    "            ) -> Dict[str,Union[Dict[str,List[float]],List[float]]]:\n",
    "        \"\"\"\n",
    "        NOTE: -- Note Very Accurate -- Need to switch profiling method.\n",
    "        \n",
    "        Runs the loop in profiler mode, ie run all three (train, valid, test) phases \n",
    "        (if set) for given number of epochs and steps and print the average time taken \n",
    "        at different stages, loop output is not printed.\n",
    "        \n",
    "        Returns the time_profile dict.\n",
    "        \n",
    "        Criteria based checkpointing is not run, ie best_model and best_score are not saved.\n",
    "        Model state is not altered (it's reloaded) if the profiler is not interrupted.\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - epochs : should be a non negative integer\n",
    "         - steps : number of batches to iterate over in each phase [train,valid,test] \n",
    "             to check if everything is working as expected, if None then all batches are\n",
    "             iterated over.\n",
    "         - define_all : If True then `torch.set_grad_enabled`, `optimizer.zero_grad` and model mode \n",
    "             ie [train,eval] have to be called where required (usually in the `train_step` function).\n",
    "         - no_cast : True, if data casting has to be manually set in the stage functions\n",
    "         - no_float : True don't apply float conversion to returned metrics.\n",
    "         - no_progress : True, don't show the progress bar.\n",
    "         - print_outcome : If False won't print profiler outcome, can be accesed from FitLoop.time_profile\n",
    "         - train_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - valid_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - test_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "        \"\"\"\n",
    "        t1 = time.perf_counter()\n",
    "        self.__loop(epochs=epochs,steps=steps, define_all=define_all, no_cast=no_cast, \n",
    "                    no_float=no_float, no_print=True, no_progress=no_progress, \n",
    "                    train_dl=train_dl, valid_dl=valid_dl, profiler=True)\n",
    "        if self.test_dl is not None or test_dl is not None:\n",
    "            self.__loop(steps=steps, define_all=define_all, no_cast=no_cast, \n",
    "                        no_float=no_float, no_print=True, no_progress=no_progress, profiler=True, \n",
    "                        test_dl=test_dl, is_test=True)\n",
    "        st = ptime(time.perf_counter() - t1)\n",
    "        if print_outcome:\n",
    "            self.print_time_profile()\n",
    "            time_profile = self.time_profile\n",
    "            self.time_profile = {}\n",
    "            print(f\"\\ntotal time: {st}\")\n",
    "            return time_profile\n",
    "        else:\n",
    "            return self.time_profile\n",
    "    \n",
    "    def run_sanity_check(self, epochs:int=1, \n",
    "            steps:int=3, print_every:int=1, use_test_dl=False,\n",
    "            display_metrics:Optional[Union[str,List[str]]]=None,\n",
    "            continue_loop:int=0, define_all:bool=False,  \n",
    "            no_print:bool=False, no_cast:bool=False,\n",
    "            no_float:bool=False, no_progress:bool=False,\n",
    "            train_dl:Optional[DataLoader]=None,\n",
    "            valid_dl:Optional[DataLoader]=None,\n",
    "            test_dl:Optional[DataLoader]=None\n",
    "           ) -> None:\n",
    "        \"\"\"\n",
    "        Runs the loop in sanity check mode, ie all three (train, valid, test) phases \n",
    "        (if set) for given number of epochs and steps.\n",
    "        Criteria based checkpointing is not run, ie best_model and best_score are not saved.\n",
    "        Model state is not altered (it's reloaded) if the sanity check is not interrupted.\n",
    "        ----\n",
    "        PARAMETERS:\n",
    "         - epochs : should be a non negative integer\n",
    "         - steps : number of batches to run in each phase [train,valid] \n",
    "             for check if everything is working, if None all batches are iterated over.\n",
    "         - use_test_dl : If False will use the validation DataLoader for the test phase,\n",
    "             else will use the test DataLoader.\n",
    "         - print_every : if 0 will not print, else will print at given epoch\n",
    "         - display_metrics : List of metrics returned in the epoch_end stage rdict that has to be \n",
    "             displayed, if None (default) all the returned metrics are displayed.\n",
    "         -  continue_loop : Will ask whether to continue training after `continue` epochs, should\n",
    "             be a positive integer.\n",
    "         - define_all : If True then `torch.set_grad_enabled`, `optimizer.zero_grad` and model mode \n",
    "             ie [train,eval] have to be called where required (usually in the `train_step` function).\n",
    "         - no_print : If True will suppress all print statements, can be used when custom logging is\n",
    "             used in the stage functions.\n",
    "         - no_cast : True, if data casting has to be manually set in the stage functions\n",
    "         - no_float : True don't apply float conversion to returned metrics.\n",
    "         - no_progress : True, don't show the progress bar.\n",
    "         - train_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - valid_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "         - test_dl : Will use this instead of DatLoader passed in the constructor call.\n",
    "        \"\"\"\n",
    "    \n",
    "        \n",
    "        print(f\"RUNNING SANITY CHECK: TRAIN LOOP - {epochs} EPOCH(s), {steps} STEP(s)\")\n",
    "        self.__loop(epochs=epochs, steps=steps, print_every=print_every, \n",
    "                    display_metrics=display_metrics, continue_loop=continue_loop,\n",
    "                    define_all=define_all, no_print=no_print, no_cast=no_cast, \n",
    "                    no_float=no_float, no_progress=no_progress, \n",
    "                    train_dl=train_dl,valid_dl=valid_dl,\n",
    "                    is_sanity_check=True)\n",
    "        if self.test_dl is not None or test_dl is not None:\n",
    "            print()\n",
    "            print(f\"RUNNING SANITY CHECK: TEST LOOP - {steps} STEP(s)\")\n",
    "            self.__loop(use_test_dl=use_test_dl, epochs=epochs, steps=steps, print_every=print_every, \n",
    "                        display_metrics=display_metrics, continue_loop=continue_loop,\n",
    "                        define_all=define_all, no_print=no_print, no_cast=no_cast, \n",
    "                        no_float=no_float, no_progress=no_progress, \n",
    "                        test_dl=test_dl,\n",
    "                        is_sanity_check=True, is_test=True)\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 4\n",
    "    \n",
    "    Functions to preserve the model state.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __save_model(self, typ:str) -> None:\n",
    "        \"\"\"\n",
    "        Save model to object or to the disk.\n",
    "        \"\"\"\n",
    "        name = self.best_model_name if typ == self._BS else self.pretrained_model_name\n",
    "        path = self.save_path/ name\n",
    "        state_dict = deepcopy(self._model.state_dict())\n",
    "        if self.save_to_disk:\n",
    "            torch.save(state_dict, path)\n",
    "            \n",
    "        elif typ == self._BS:\n",
    "            self.best_model_state_dict = state_dict\n",
    "        elif typ == self._PR:\n",
    "            self.pretrained_model_state_dict = state_dict\n",
    "        else:\n",
    "            logging.warning(\"model save failed\")\n",
    "        \n",
    "    def __load_model(self, typ:str):\n",
    "        \"\"\"\n",
    "        Load model from the object or from the disk.\n",
    "        \"\"\"\n",
    "        name = self.best_model_name if typ == self._BS else self.pretrained_model_name\n",
    "        path = self.save_path/ name\n",
    "        if self.save_to_disk:\n",
    "            state_dict = torch.load(path, map_location=self.device)\n",
    "        elif typ == self._BS:\n",
    "            state_dict = self.best_model_state_dict\n",
    "        else:\n",
    "            state_dict = self.pretrained_model_state_dict\n",
    "        self._model.load_state_dict(state_dict)\n",
    "        if self.configure_optimizer is None:\n",
    "            print(\"please reconfigure FitLoop.optimizer before training\")\n",
    "        else:\n",
    "            self.configure_optimizer(self)\n",
    "    \n",
    "    def reset(self, reset_model:bool=True) -> None:\n",
    "        \"\"\"\n",
    "        Resets FitLoop to initial state.\n",
    "        Parameters reset:\n",
    "            - model, to pretrained state if `reset_model`\n",
    "            - epoch_num, to 0\n",
    "            - best_score to ‚àìinf\n",
    "        FitLoop.optimizer param groups will have to be set again\n",
    "        \"\"\"\n",
    "        if reset_model:\n",
    "            self.__load_model(self._PR)\n",
    "        self.epoch_num = 0\n",
    "        self.best_score = self.criteria_direction * float('-inf')\n",
    "        self.metrics = None\n",
    "        \n",
    "        \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 5\n",
    "    \n",
    "    Functions to preserve the FitLoop object state so that training can be resumed.\n",
    "    \"\"\"\n",
    "    \n",
    "    def save(self, path, only_model=False):\n",
    "        \"\"\"\n",
    "        TODO : save the FitLoop state, if only_model then save only model.\n",
    "        \"\"\"\n",
    "        print(\"NOT IMPLEMENTED YET\")\n",
    "        pass\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\"\n",
    "        TODO : load the FitLoop state, if only model then load the model \n",
    "            state dict.\n",
    "        \"\"\"\n",
    "        print(\"NOT IMPLEMENTED YET\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 6\n",
    "    \n",
    "    Functions to delete stored model weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def del_pretrained(self) -> None:\n",
    "        \"\"\"\n",
    "        Deletes the pretrianed model state dict from the disk if \n",
    "        `save_to_disk` else states attribute to None\n",
    "        \"\"\"\n",
    "        if self.save_to_disk:\n",
    "            (self.save_path/self.pretrained_model_name).unlink()\n",
    "        else:\n",
    "            self.pretrained_model_state_dict = None\n",
    "        \n",
    "    def del_best_model(self) -> None:\n",
    "        \"\"\"\n",
    "        Deletes the best model state dict from the disk if \n",
    "        `save_to_disk` else states attribute to None\n",
    "        \"\"\"\n",
    "        if self.save_to_disk:\n",
    "            (self.save_path/self.best_model_name).unlink()\n",
    "        else:\n",
    "            self.best_model_state_dict = None\n",
    "            \n",
    "    # ---------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    SECTION: 7\n",
    "    \n",
    "    Getters for metrics\n",
    "    \"\"\"\n",
    "    @property\n",
    "    def M(self):\n",
    "        return self.metrics\n",
    "    \n",
    "    @property\n",
    "    def train_metrics(self):\n",
    "        return self.metrics.train\n",
    "    \n",
    "    @property\n",
    "    def valid_metrics(self):\n",
    "        return self.metrics.valid\n",
    "    \n",
    "    @property\n",
    "    def test_metrics(self):\n",
    "        return self.metrics.test\n",
    "    \n",
    "    @property\n",
    "    def plot(self,*args,**kwargs):\n",
    "        return self.metrics.plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1477,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T02:48:53.765417Z",
     "start_time": "2020-05-09T02:48:53.760402Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import FakeData\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Batch Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T05:17:38.943815Z",
     "start_time": "2020-05-07T05:17:38.930490Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def common_step(state):\n",
    "#     print(f\"{state.phase}_step, bn: {state.batch_num} en: {state.epoch_num}, \",end=\"\")\n",
    "    X, y = state.batch\n",
    "    y_ = state.model(X)\n",
    "    loss = state.loss_function(y_,y)\n",
    "#     print(\"loss\",loss.item())\n",
    "    r_loss = loss.item() * state.batch_size\n",
    "    r_corr = (y_.argmax(dim=1) == y).sum().item()\n",
    "    return loss, r_loss, r_corr\n",
    "\n",
    "def train_step(state):\n",
    "    loss, r_loss, r_corr = common_step(state)\n",
    "    loss.backward()\n",
    "    state.optimizer.step()\n",
    "    return {'r_loss':r_loss,'r_corr':r_corr}\n",
    "\n",
    "def valid_step(state):\n",
    "    loss, r_loss, r_corr = common_step(state)\n",
    "    return {'r_loss':r_loss,'r_corr':r_corr}\n",
    "\n",
    "def test_step(state):\n",
    "    loss, r_loss, r_corr = common_step(state)\n",
    "    return {'r_loss':r_loss,'r_corr':r_corr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Epoch Start Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T02:30:23.312588Z",
     "start_time": "2020-05-07T02:30:23.298636Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def common_epoch_start(state):\n",
    "#     print(f\"\\n{state.phase}_epoch_start, # {state.epoch_num}\")\n",
    "    return {'dummy':'dict'}\n",
    "    \n",
    "def train_epoch_start(state):\n",
    "    return common_epoch_start(state)\n",
    "\n",
    "def valid_epoch_start(state):\n",
    "    return common_epoch_start(state)\n",
    "\n",
    "def test_epoch_start(state):\n",
    "    return common_epoch_start(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Epoch End Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T02:30:24.831128Z",
     "start_time": "2020-05-07T02:30:24.819422Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def common_epoch_end(state):\n",
    "#     print(f\"{state.phase}_epoch_end, # {state.epoch_num}\")\n",
    "    r_loss = state['r_loss']\n",
    "    r_corr = state['r_corr']\n",
    "    \n",
    "#     print('r_loss len',len(r_loss))\n",
    "#     print('r_corr len',len(r_corr))\n",
    "    \n",
    "    e_loss = r_loss.sum()/state.size\n",
    "    e_accu = r_corr.sum()/state.size\n",
    "    \n",
    "#     print('loss',e_loss)\n",
    "#     print('accu',e_accu)\n",
    "    \n",
    "    return {'loss':e_loss, 'accu':e_accu}\n",
    "    \n",
    "def train_epoch_end(state):\n",
    "    return common_epoch_end(state)\n",
    "\n",
    "def valid_epoch_end(state):\n",
    "    return common_epoch_end(state)\n",
    "\n",
    "def test_epoch_end(state):\n",
    "    return common_epoch_end(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FitLoop - Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1765,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:43:29.544401Z",
     "start_time": "2020-05-09T05:43:29.391298Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Basic setup with FakeData for testing.\n",
    "\"\"\"\n",
    "\n",
    "def get_dl(batch_size=4, sz=[100,20,30]):\n",
    "    sets = ['train','valid','test']\n",
    "    TR, VA, TE = sets\n",
    "    class_names = ['a','b','c','d']\n",
    "    num_classes = 4\n",
    "\n",
    "    sz = {s:z for s, z in zip(sets,sz)} # a multiple of batch size\n",
    "    ds = {s:FakeData(size=sz[s], transform=ToTensor(), num_classes=num_classes) for s in sets}\n",
    "    dl = {s:DataLoader(ds[s],batch_size=batch_size) for s in ds}\n",
    "    return dl\n",
    "\n",
    "model = resnet18()\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    \n",
    "dummy = nn.Sequential(\n",
    "    nn.Conv2d(3,1,3,10),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(529,4)\n",
    ")\n",
    "\n",
    "model = dummy\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# ----------------------------------------------\n",
    "\n",
    "def configure_optimizer(self):\n",
    "    parameters = self.model.parameters()\n",
    "    self.optimizer.param_groups.clear()\n",
    "    self.optimizer.add_param_group({'params': parameters})\n",
    "    \n",
    "dl = get_dl(batch_size=5,sz=[52,12,23])\n",
    "fl_dict = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"loss_function\": loss_function,\n",
    "    \"train_dl\":dl[TR],\n",
    "    \"valid_dl\":dl[VA],\n",
    "    \"test_dl\":dl[TE],\n",
    "#     \"train_step\":train_step,\n",
    "#     \"valid_step\":valid_step,\n",
    "#     \"test_step\":test_step,\n",
    "#     \"train_epoch_start\":train_epoch_start,\n",
    "#     \"valid_epoch_start\":valid_epoch_start,\n",
    "#     \"test_epoch_start\":test_epoch_start,\n",
    "#     \"train_epoch_end\":train_epoch_end,\n",
    "#     \"valid_epoch_end\":valid_epoch_end,\n",
    "#     \"test_epoch_end\":test_epoch_end,\n",
    "#     \"criteria\": \"accu\"\n",
    "    \"configure_optimizer\":configure_optimizer,\n",
    "}\n",
    "\n",
    "trainer = FitLoop(**fl_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1783,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:45:24.338092Z",
     "start_time": "2020-05-09T05:45:24.171196Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3iV5fnA8e9zTvYiIYOEDMLeCSMJAQe4GGJxsBW3Io5Wba2ora22aq39OauIuJUlAoIDRRwUZSfMsLKAECCTkL3z/P54Q0zIAUKSk5Nxf64rF+R93jy5cyDvfZ6ttNYIIYTouEy2DkAIIYRtSSIQQogOThKBEEJ0cJIIhBCig5NEIIQQHZydrQO4WD4+Pjo0NNTWYQghRJsSGxubpbX2tVTW5hJBaGgoMTExtg5DCCHaFKXU0XOVSdeQEEJ0cJIIhBCig5NEIIQQHZzVxgiUUh8A1wEZWutB57kvEtgCTNdaL7dWPEKIjqu8vJzU1FRKSkpsHYrVOTk5ERQUhL29fYO/xpqDxR8BbwKfnOsGpZQZ+Dew1opxCCE6uNTUVNzd3QkNDUUpZetwrEZrTXZ2NqmpqXTv3r3BX2e1riGt9Qbg1AVu+z2wAsiwVhxCCFFSUoK3t3e7TgIASim8vb0vuuVjszECpVQgcCMwvwH3zlZKxSilYjIzM60fnBCi3WnvSeCMxvycthwsfg2Yq7WuvNCNWusFWusIrXWEr6/F9RAXFJ+ez3Nf76ek/ILfTgghOhRbJoIIYKlS6ggwBZinlLrBWt8sNaeI9349TOzRHGt9CyGEsOj06dPMmzfvor/u2muv5fTp01aIqC6bJQKtdXetdajWOhRYDjygtV5lre8X1d0bO5NiY2KWtb6FEEJYdK5EUFl5/h6KNWvW4Onpaa2walhz+ugSYAzgo5RKBf4O2ANorS84LtDc3BztGBLsycak7Jb+1kKIDu6JJ54gKSmJIUOGYG9vj5ubGwEBAezatYv9+/dzww03cOzYMUpKSnj44YeZPXs28NuWOgUFBUyYMIFLL72UTZs2ERgYyOrVq3F2dm6W+KyWCLTWMy/i3jusFUdto3r58OZPCeQWl9PJueFzbIUQ7cezX+1j/4m8Zq1zQFcP/v67gecsf/HFF4mLi2PXrl2sX7+eiRMnEhcXVzPF84MPPqBz584UFxcTGRnJ5MmT8fb2rlNHQkICS5Ys4d1332XatGmsWLGCWbNmNUv8HWpl8SU9vanSsDVZWgVCCNuJioqqM8//jTfeIDw8nOjoaI4dO0ZCQkK9r+nevTtDhgwBYPjw4Rw5cqTZ4mlzu482xdAQL5ztzWxMzGLsQH9bhyOEsIHzvXNvKa6urjV/X79+PT/88AObN2/GxcWFMWPGWFwH4OjoWPN3s9lMcXFxs8XToVoEDnYmIrt3lnECIUSLcnd3Jz8/32JZbm4uXl5euLi4cPDgQbZs2dLC0XWwFgEY3UP/+vYg6XkldPFwsnU4QogOwNvbm0suuYRBgwbh7OxMly5dasrGjx/P/PnzCQsLo2/fvkRHR7d4fB0vEfTyAWBTUhY3Dg2ycTRCiI5i8eLFFq87Ojry7bffWiw7Mw7g4+NDXFxczfXHHnusWWPrUF1DAAMCPPBysWdjonQPCSEEdMBEYDIpRvb0ZmNiFlprW4cjhBA21+ESAcConj6czC3hcFahrUMRQgib65CJ4Mw4gcweEkKIDpoIQr1dCPR0Zv1BOQZBCCE6ZCJQSnFdWADr4zPJzC+1dThCCGFTHTIRAEyNCKKySrNq53FbhyKEEHW4ubkBcOLECaZMmWLxnjFjxhATE9Ms36/DJoJefu4MCfbk89hjMntICNEqde3aleXLl1v9+3TYRAAwLSKY+PQC9qTm2joUIUQ7Nnfu3DrnETzzzDM8++yzXHXVVQwbNozBgwezevXqel935MgRBg0aBEBxcTEzZswgLCyM6dOnN+teQx1uZXFt14UH8I+v9/F57DHCg61/+IMQohX49glI29u8dfoPhgkvnrN4xowZPPLIIzzwwAMALFu2jO+++45HH30UDw8PsrKyiI6OZtKkSec8c/jtt9/GxcWFPXv2sGfPHoYNG9Zs4XfoFoGHkz3jB/rz5a4TcpaxEMJqhg4dSkZGBidOnGD37t14eXkREBDAU089RVhYGFdffTXHjx8nPT39nHVs2LCh5vyBsLAwwsLCmi2+Dt0iAJgaEcyqXSf4fn86k8K72jocIYS1needuzVNmTKF5cuXk5aWxowZM1i0aBGZmZnExsZib29PaGioxe2naztXa6GpOnSLAGBkD28CPZ35POaYrUMRQrRjM2bMYOnSpSxfvpwpU6aQm5uLn58f9vb2/Pzzzxw9evS8X3/55ZezaNEiAOLi4tizZ0+zxdZxEkFqLCy7HUoL6lw2mRSThwfxa2IWqTlFNgpOCNHeDRw4kPz8fAIDAwkICOCWW24hJiaGiIgIFi1aRL9+/c779ffffz8FBQWEhYXx0ksvERUV1WyxdZyuobIC2L8KwqZBv4l1iqZFBPHmTwks3XaMx8b1tVGAQoj2bu/e3wapfXx82Lx5s8X7CgqMN6yhoaE12087OzuzdOlSq8RltRaBUuoDpVSGUiruHOW3KKX2VH9sUkqFWysWAEJGgqMHxK+tVxTk5cIVff1Yuv0YZRVVVg1DCCFaG2t2DX0EjD9P+WFgtNY6DPgnsMCKsYCdA/S80kgEFhaQzRrZjayCUr7fn2bVMIQQorWxWiLQWm8ATp2nfJPWOqf60y2A9Y8L6zMOCtLg5O56RaN7+xLc2ZlPN59/wEYI0TZ1lB0EGvNztpbB4rsBy2e1AUqp2UqpGKVUTGZmZuO/S69rAGWxe8hkUtwc1Y2th0+RkG75kGkhRNvk5OREdnZ2u08GWmuys7Nxcrq489iVNV8YpVQo8LXWetB57rkCmAdcqrW+4AEBERERukkbLb13NegquPenekXZBaWM/NdP3DwihGcmDWz89xBCtCrl5eWkpqZecJ5+e+Dk5ERQUBD29vZ1riulYrXWEZa+xqazhpRSYcB7wISGJIFm0Xsc/PwcFGSAm1+dIm83R64d7M+K2FT+PK4vro4dZ1KVEO2Zvb093bt3t3UYrZbNuoaUUiHASuBWrXV8i33jPuOMPxO+t1g8K7ob+aUVfLn7RIuFJIQQtmTN6aNLgM1AX6VUqlLqbqXUHKXUnOpb/gZ4A/OUUruUUs2zsfaF+A8G964WxwkAhnfzop+/Owu3HG33/YlCCAFW7BrSWs+8QPk9wD3W+v7npBT0GQt7l0NFmTGttE6x4pbobjy9Ko5dx04zNMSrxUMUQoiW1FpmDbWsPuONlcZHN1osvnFoIK4OZhZuSWnhwIQQouV1zETQfTTYOUH8dxaL3RztuGFoIF/vOcHporIWDk4IIVpWx0wEDi7Q62qIWwmVFRZvmRXdjdKKKpbHprZwcEII0bI6ZiIAGHIzFGZA4g8Wi/sHeBDRzYtFW1OoqpJBYyFE+9VxE0HvseDiA7sWnfOWWdHdOJxVyKakllniIIQQttBxE4HZHsKmw6FvodDyg37CYH86uzqwcIvsPySEaL86biIAo3uoqhz2fm6x2NHOzNSIINYdSCctt/0vTRdCdEwdOxH4D4KA8PN2D90S1Y3KKs1n2+UoSyFE+9SxEwHAkFmQtgfS9losDvF24fI+vizZlkJFpRxaI4RofyQRDJ4CZgfYtfict8waEUJaXgk/HsxowcCEEKJlSCJw6Qx9J8Cez4wtJyy4sp8fAZ2cWLRVVhoLIdofSQQAQ2+DomzYv9pisZ3ZxIzIEDbEZ3I0u7CFgxNCCOuSRADGWcbevWHLWxbPMwaYHhmM2aRYvE1aBUKI9kUSAYDJBNH3w4mdkLLZ4i3+nZy4pn8XPo9JpbSisoUDFEII65FEcEb4THD2gs1vnfOWW6JDOFVYxndxaS0YmBBCWJckgjMcXCDiLjj4DZxKtnjLJT19CPV2kZXGQoh2RRJBbZH3gskOtr5jsdhkUsyMCmH7kRzi0/NbODghhLAOSQS1eQTAoMmwcyEUn7Z4y5ThQTiYTSyWqaRCiHZCEsHZRj5gnF624xOLxd5ujowf5M+KHakUl8mgsRCi7ZNEcLaAcAi9DLbOh8pyi7fcPCKE/JIKvt5zooWDE0KI5ieJwJJRf4C848YJZhaM6N6Znr6usqZACNEuWC0RKKU+UEplKKXizlGulFJvKKUSlVJ7lFLDrBXLRet1Nfj2g03/tbjATCnFzSO6sTPlNPtP5NkgQCGEaD7WbBF8BIw/T/kEoHf1x2zgbSvGcnFMJhj5EKTvheT1Fm+ZPCwQBzsTi7fJVFIhRNtmtUSgtd4AnDrPLdcDn2jDFsBTKRVgrXguWtg0cOsCm96wWOzp4sB1gwNYtfMEhaUVLRycEEI0H1uOEQQCtU97Sa2+Vo9SarZSKkYpFZOZmdkiwWHnCCPug6SfIM1i7xY3jwihoLSCr3bLoLEQou2yZSJQFq5Z3PFNa71Aax2htY7w9fW1cli1RNwF9q7GWIEFw7t50aeLG0tk0FgI0YbZMhGkAsG1Pg8CWtdba2cvGHYbxC2H3OP1ipVSzIgMYXdqLvtO5NogQCGEaDpbJoIvgduqZw9FA7la65M2jMey6Dmgq2D7uxaLb6oeNF66Tc40FkK0TdacProE2Az0VUqlKqXuVkrNUUrNqb5lDZAMJALvAg9YK5Ym8QqFfhMh5kMoK6pX7OniwMTBAazaeZyiMhk0FkK0PdacNTRTax2gtbbXWgdprd/XWs/XWs+vLtda6we11j211oO11jHWiqXJoh+AktOwZ6nF4plRIeSXVvD1ntbXoBFCiAuRlcUNETISAobAlrehqqpecWSoFz19XVkqg8ZCiDZIEkFDKGW0CrLijemk9YqN7al3pJzmYJqsNBZCtC2SCBpq4I3g5g9b5lksnjzM2J5aBo2FEG2NJIKGsnOAqHsg6UfIOFiv2MvVgfGD/Fm5I5WSctmeWgjRdkgiuBjD7wI7J2OLagtmRAaTV1IhZxoLIdoUSQQXw9UbBk+FPZ9BcU694uge3oR0dmHpdhk0FkK0HZIILlbUbCgvgl2L6xWZTIrpkcFsST7F4axCGwQnhBAXTxLBxQoIM6aTbnvX4lTSKcODMJsUy2Jk0FgI0TZIImiMqHsh5zAk/lCvqIuHE1f09ePzmFTKK+snCiGEaG0kETRG/0nGVNJtCywWz4gMJquglJ8OZrRwYEIIcfEkETSG2d7YojpxHWQn1Sse09cXP3dHPtsu3UNCiNZPEkFjDb8DTPaw/b16RXZmE1Mjglh/KIOTucUtH5sQQlwESQSN5d4FBt4AOxdCaUG94ukRIVRpWB6TaoPghBCi4SQRNEXkvVCaB3uX1SsK8XZhZA9vlsUeo6rK4sFrQgjRKkgiaIrgKPAfDNvfB13/YT8jKphjp4rZnJxtg+CEEKJhJBE0hVJGqyA9DlK21CseN9AfDyc7GTQWQrRqkgiaavAUcOxkcdDYyd7MjUMD+W5fGqeLymwQnBBCXJgkgqZycIUhN8P+1VBQf93AtMhgyiqqWLXzuA2CE0KIC5NE0Bwi74aqctjxcb2igV07MSjQg89iUtEWxhGEEMLWJBE0B5/e0GOMccB9Zf0D7KdHhnDgZB5xx+X0MiFE62PVRKCUGq+UOqSUSlRKPWGhvJNS6iul1G6l1D6l1J3WjMeqIu+FvOMQ/129oknhXXG0M8n21EKIVslqiUApZQbeAiYAA4CZSqkBZ932ILBfax0OjAFeVko5WCsmq+ozHjwCYfu79Yo6OdszcXAAX+46QXGZnF4mhGhdrNkiiAIStdbJWusyYClw/Vn3aMBdKaUAN+AUUL9vpS0w28HwOyF5PWQl1iueFhlMfmkFa/aebPnYhBDiPKyZCAKB2hPoU6uv1fYm0B84AewFHtZat929m4fdZuw/FPNBvaIR3TsT6u3CZ3JOgRCilbFmIlAWrp09bWYcsAvoCgwB3lRKedSrSKnZSqkYpVRMZmZm80faXNy7wIBJsGshlBXVKVJKMS0ymG2HT5GcWX9vIiGEsBVrJoJUILjW50EY7/xruxNYqQ2JwGGg39kVaa0XaK0jtNYRvr6+Vgu4WUTeAyW5ELe8XtGUYWdOL5ON6IQQrYc1E8F2oLdSqnv1APAM4Muz7kkBrgJQSnUB+gLJVozJ+kJGgt8A4yjLs9YN+FWfXrY8Vk4vE0K0HlZLBFrrCuAhYC1wAFimtd6nlJqjlJpTfds/gVFKqb3Aj8BcrXWWtWJqEUoZC8zS9sDx2HrFcnqZEKK1sbNm5VrrNcCas67Nr/X3E8BYa8ZgE2HTYd3fjf2HgiLqFJ05vWzZ9mOMG+hvowCFEOI3srLYGhzdIXwGxK2EwrpbUNuZTUwZHsTPhzJIyy2xUYBCCPGbBiUCpdTDSikPZXhfKbVDKdX+3sk3p8h7oLIUdn5ar2haRLBxelmsTCUVQtheQ1sEd2mt8zC6cXwxZvu8aLWo2gO//tDtUmNNQVXd1cShPq6M7OHNZzFyepkQwvYamgjOrAm4FvhQa70by+sERG1R98Dpo5D4Q72iM6eXbUqS08uEELbV0EQQq5T6HiMRrFVKuQMy//FC+l0Hbv7GVNKzjBvoj6eLPUtkIzohhI01NBHcDTwBRGqtiwB7jO4hcT5mexh+h9EiOFV3ecSZ08u+35dGdkGpbeITQgganghGAoe01qeVUrOAvwK51gurHRl+OyiTxf2HZkSGUF6p+UJOLxNC2FBDE8HbQJFSKhx4HDgKfGK1qNoTj67Q/zrYuRDKi+sU9fV3Z2iIJ0u2pcjpZUIIm2loIqjQxpPqeuB1rfXrgLv1wmpnIu+B4hyIW1GvaGZkCEmZhcQezbFBYEII0fBEkK+UehK4Ffim+tAZe+uF1c6EXga+/WDbgnr7D00MC8DN0Y7F22TQWAhhGw1NBNOBUoz1BGkY5wr8x2pRtTdKGa2Ck7shNaZOkaujHZOGdOWbPSfJLSq3UYBCiI6sQYmg+uG/COiklLoOKNFayxjBxQifAQ7uRqvgLDdHhVBaUcXKnbI9tRCi5TV0i4lpwDZgKjAN2KqUmmLNwNodR3cYcjPs+wIK6u48OiiwE+FBnVi8VQaNhRAtr6FdQ3/BWENwu9b6NozziJ+2XljtVOQ9UFUOsR/XK7p5RAgJGQUyaCyEaHENTQQmrXXtt7HZF/G14gzfPtDjCmNNQWXd8YDfhXfF3dGOxVtl0FgI0bIa+jD/Tim1Vil1h1LqDuAbzjpnQDRQ1GzIPwEHv6lz2cXBjhuGBvL13pOcLiqzUXBCiI6ooYPFfwYWAGFAOLBAaz3XmoG1W33GQacQi/sP3TwihLKKKlbskJXGQoiW0+DuHa31Cq31H7XWj2qtv7BmUO2ayWwcZXn0V0iLq1PUP8CDoSGeLN56VAaNhRAt5ryJQCmVr5TKs/CRr5TKa6kg251ht4GdM2ydX6/o5ihjpfHWw6dsEJgQoiM6byLQWrtrrT0sfLhrrT1aKsh2x6UzhE+HvZ/XO8ryd+Fd6eRsz6dbjtooOCFERyMzf2wl6j6oKIEdH9W57GRvZlpEEGvj0sjIkzONhRDWZ9VEoJQar5Q6pJRKVEo9cY57xiildiml9iml/mfNeFqVLgOg+2jY/n69qaS3jOhGRZVmyTY501gIYX1WSwTVG9O9BUwABgAzlVIDzrrHE5gHTNJaD8RYudxxRN8PecfhwFd1Lof6uDK6jy+Ltx2lvFIOghNCWJc1WwRRQKLWOllrXQYsxdjGurabgZVa6xSAsxattX+9x4FXd4uDxrdGdyM9r5Qf9qfbIDAhREdizUQQCNTu20itvlZbH8BLKbVeKRWrlLrNUkVKqdlKqRilVExmZqaVwrUBk8lYYHZsKxzfUafoin5+BHo688lmGTQWQliXNROBsnDt7MnxdsBwYCIwDnhaKdWn3hdpvUBrHaG1jvD19W3+SG1p6CxwcKvXKjCbFLdEh7A5OZvEjHwbBSeE6AismQhSgeBanwcBJyzc853WulBrnQVswFi53HE4ecDQW43Ty/LqvjzTI4JxMJukVSCEsCprJoLtQG+lVHellAMwA/jyrHtWA5cppeyUUi7ACOCAFWNqnaLngK6Cre/Uuezt5sh14QEsj00lt1gOrRFCWIfVEoHWugJ4CFiL8XBfprXep5Sao5SaU33PAeA7YA/GeQfvaa3jzlVnu+UVCv0nQeyHUFpQp+iuS7pTVFbJ5zEylVQIYR1WXUegtV6jte6jte6ptX6++tp8rfX8Wvf8R2s9QGs9SGv9mjXjadVG/R5KcmHnwjqXBwV2Iiq0Mx9tOkJllew/JIRofrKyuLUIioDgEbBlHlRV1im669JQUnOKWSdTSYUQViCJoDUZ+RCcPlpvgdk1A/wJ8nLmg42HbRSYEKI9k0TQmvSbaCww2/xmnctmk+L2kaFsO3yKuOO5NgpOCNFeSSJoTUxmiH4AUrfD0c11iqZFBuPiYObDjUdsE5sQot2SRNDaDJ0FLt7w66t1LndytmfK8CC+2n1CdiUVQjQrSQStjYMLjLgfEtbWO8Hsrku6U15VxYebjtgmNiFEuySJoDWKusfYdmJj3dm0oT6uTBjkz8ItR8kvkQVmQojmIYmgNXL2gog7jW0nTtWdKXTf5T3JL6lgybYUGwUnhGhvJBG0VtEPgskONr1R53J4sCcje3jz/q+HKauQswqEEE0niaC18giA8JmwcxHk111INmdMT9LzSlm167iNghNCtCeSCFqzSx6GqnLY8lady5f39qF/gAcLNiRTJdtOCCGaSBJBa+bdEwbeBNveg8KsmstKKeaM7kFiRgE/HuxYh7oJIZqfJILWbvTjUF4Em/5b5/LEwQEEeTnz1s+JaC2tAiFE40kiaO18+8LgKbDt3TqtAjuziQfG9GLXsdNsSMg6TwVCCHF+kgjagssfh4pi2Ph6nctThgcR6OnMaz/ES6tACNFokgjaAt8+MGgKbH8PCjJrLjvYmXjgip7sTDnNL9IqEEI0kiSCtmL041BRApvqtgqmDg+maycnaRUIIRpNEkFb4dMbBk81ZhDVWldgtAp6sSPlNL8mSqtACHHxJBG0JaPnGusKNrxU5/LUiCACOjnx2g8J0ioQQlw0SQRtiXdPGH4HxH4E2Uk1lx3tzDxwRS9ij+awPj7znF8uhBCWSCJoa0bPBbMj/PiPOpenRwTTzduFf397UA65F0JcFKsmAqXUeKXUIaVUolLqifPcF6mUqlRKTbFmPO2Cmx+M+j3sXwWpsTWXHexMPDa2LwfT8lm1U/YgEkI0nNUSgVLKDLwFTAAGADOVUgPOcd+/gbXWiqXdGfUQuPrCur9BrTGBiYMDGBzYiVfWxVNSXmnDAIUQbYk1WwRRQKLWOllrXQYsBa63cN/vgRWAbJrTUI7uRhfR0V8hYV3NZZNJ8eSEfhw/Xcynm4/aMEAhRFtizUQQCByr9Xlq9bUaSqlA4EZg/vkqUkrNVkrFKKViMjNlMBSAYbdD5x7w/V+h8rfTykb18uHyPr68+XMiuUVyipkQ4sKsmQiUhWtnj2K+BszVWp+3H0NrvUBrHaG1jvD19W22ANs0OwcY9y/IOgRb36lT9MT4fuSVlDNvfaKNghNCtCXWTASpQHCtz4OAE2fdEwEsVUodAaYA85RSN1gxpvalzzjodQ2sf7HOIrMBXT2YPCyIDzYeJimzwIYBCiHaAmsmgu1Ab6VUd6WUAzAD+LL2DVrr7lrrUK11KLAceEBrvcqKMbUvSsH4F42tJ354pk7R3PH9cLI388yX+2SRmRDivKyWCLTWFcBDGLOBDgDLtNb7lFJzlFJzrPV9OxyfXjDyQdi9GI5tq7ns6+7IH6/pwy8JWazdl36eCoQQHZ1qa+8WIyIidExMjK3DaF1KC+DNCHDrAvf+BCYzABWVVUx841cKSiv44Y+jcXYw2zhQIYStKKVitdYRlspkZXF74OgGY5+Dk7uMraqr2ZlNPHv9QI6fLubt/yWdpwIhREcmiaC9GDQZel0NPzwLOb+tIYju4c2k8K7M/18SyTJwLISwQBJBe6EUXPeq8efXj9RZcfzXif1xsjMxd8UeqmQfIiHEWSQRtCeeIXD1M5D0E+xeUnPZz8OJp68bwPYjOXyy+YiNghNCtFaSCNqbiLshZCR892SdtQVThgcxpq8v//7uECnZRTYMUAjR2kgiaG9MJpj0XygvrtNFpJTihRsHYzYp5q7YI2sLhBA1JBG0Rz694eq/w6E1EPNBzeWuns48dW1/Nidns3Brig0DFEK0JpII2qsR90PPq2DtU5BxsObyzKhgLuvtw/Pf7Cc+Pd+GAQohWgtJBO2VyQQ3vA0ObrDibigvAYwuopenhePmaMdDi3dQXCbnFgjR0UkiaM/cuxjJID0Ofvh7zWU/dydemTaE+PQC/vH1fhsGKIRoDSQRtHd9xsKIObB1Puz7bT+/y/v4cv+YnizZlsLXe87eFFbsST3NrPe2kpFX0qz1WmMdhzXOqLbGZAKZoNB6SSLoCK75BwRFwqoHIP23FsAfr+nDsBBPnlyxV7arPsumpGx+TcziocU7Ka+sapY61+1PZ/hz65r1tf4u7iTD/rmuWVeNfxeXRuTzP3LsVPNNM167L41RL/7EydziZq3z8pd+btZkvXZfGle+vJ7sgtJmrXPcqxvIKSxrtjqbmySCjsDOEaZ9auxJtHQmFJ0CwN5s4o2ZQ7G3M3HvxzFyolktabklmBRsO3KKF9YcaJY6NyVlkVNUzp8/391s7+K3JJ8it7i8WVeNb0nOJquglL+simu2d/Gbk7I5mVvCM1/ua5b6ADYmZpFyqojnvmmef58zdSZnFvLv7w5e+OYG+iUhk0Pp+by87lCz1dncJBF0FB4BMH0h5B43Bo+rjEHiIC8X5s8azrGcIh5asoOKZnr329Zl5JfQ3ceVO0aF8uHGI6zedbzJdR48mY+Lg5kdKad5/9fkZogSEjLycbQzsf1IDgu3Ns851QkZ+diZFBviM1m9q3m6DRMy8jEpWLsvnXX7m2db9MQMoxX05e4TbEzMatY6l8WkEns0pzqneuQAACAASURBVFnqTMooBGDx1hT2nchtljqbmySCjiQ4Cia+bGxB8f3TNZejunfmuRsG8UtCFs8307vfti49r5QuHk78ZWJ/IkO9eGLFXg6m5TW6Pq01B9LyuH5IV64Z0IX/+z6+5qHTFPHpBfwuvCuX9/Hl398eJDWn6d058ekFTArvypBgT/7x9X5ONUOXRmKGUWffLu78fXUchaUVzVLndWEBdPN24enVcZRWNH0GXGJGARMG+ePv4cTfVsc1S8stKbOAsQO64OXiwN9Xt86DoiQRdDTDb4eo+2DLW7DpvzWXp0eGcNcl3flw4xEWNdM7y7YsPa8Efw8n7M0m3rp5GO5OdjywaEejH2DpeaWcLiqnf4AHz984CBcHM481sYsop7CMzPxS+nRx44UbBwHw5Mq9TXrQnC4y6uzr786LkweTV1zOc980bWZZbnE56Xml9A/w4IWbBnEit4TXfohvUp15JeVk5JcysGsnnpk0kOTMQt7d0LRW1pk6w4I8+et1/dl3Io/FTfxdOFPn0BAvHh/fl5ijOaxqhtZlc5NE0BGN/xcMuB6+/yvs/qzm8lPX9uOKvr48vSqONXtP2jBA29Jak5FXip+HE2Bs2vfajCEczirkb6sb18d94KTRmujn74GfuxPPThrIrmOneWdD48+JOLMgsE8Xd4K8XJg7oR+/JGTxeUxqo+tMqG6l9OniTj9/D+aM7snKHcf5JSGz0XWeafn08nNjeLfOzIwK4YONR5rUTVK7ziv6+jFhkD///SmxSQPcSbXqnDg4gEt6efOftYeaNHBcu86pw4MJD+rEv9YcpKAZWkTNSRJBR2Qyw40LIPQyWP0AJP4AGAfZzLtlOMNCvHh46U7+F9/4X/62LKeonLLKKrq6/jZeMqqnD3+4sjcrdqSyIvbiH7QHqruV+gW4AzApvCvXDvbnle/j2ZN6ulFxxtd6aAPMGtGNEd0784+v9zf6gZiQ/tuDC+ChK3vRw9eVucv3kFfSuMkEiRlGwurtZ8T5xPh+eLk48PjyPY2ekZVYHWfv6jifvm4AZpPiqS8a3yKqnVyUUjw7aRDF5ZU834TB6KRMY3ygp68rJpPi2esHkZFfyqvrmtYiam6SCDoqeyeYsQh8+8Nnt8HRTQA4O5h5/45Ievu5M+fTWGKPnrJxoC0vPa+EcaZt3LJ+NBz+peb6H67qzYjunXl6ddxFTwE9cDKfoE6OeJQZg5pnNgH0dXfk4aW7GtXlFJ+Wj7ujHQFuxq+xyWSsGlfAH5ftalS3U3y6MaAd6OkMgJO9mZenhpOWV8I/vmpcF1FCegFO9iYCvYw6O7nY89wNg9h3Io95PzeuRZSYWYCDnYngzi6AsY/W3PFNaxElZRbiYDYRXB1nLz83o0W08zg/H8poZJ0F2JtVTZxDgj25ZUQIH248zO5jjXsDYA2SCDoyp04wazl4dIWFk2seep2c7fn4rij8Ozlxx4fb2ZHSPLMn2oq0vBIGmY5griqDZbdCtvGwMpsUr88YipO9mQcXXdz2HAdP5nG3+yZ4dUBNC8zTxYFXpw/hSHYhz3518V1O8en53NEpFvVSDzixCzBmgT17/UC2H8lpVLdTYkYB0zwPYnorsuaku6EhXjwwphfLY1MbNeMnIaOASZ5HMC+8oWbq8vhB/lw/pCv//SmhUV1EiRkFjPU8iXn1/VBmvOu+NbobUd07889v9pOWe/FrCxIzChjtlYXdT89ApdH6eejKXvTyc+MvK/c2qjsnKaOAaK987Le+BVVG62fuhH74ujsyd0XjW0TNzaqJQCk1Xil1SCmVqJR6wkL5LUqpPdUfm5RS4daMR1jg7g93fGMcarNoKiSvB8DX3ZGF94ygs6sDs97byqak5pme1xZk5JUQrDKodPICFCyZAcXGuzf/Tk68PC2cQ+n5PN7A7bxLyitJzipkBPtAV8GKeyDnCGAcJfrgmF4si0m9qBXeWmvi0/MZbd4LZQWw7DYoNhL2jUMDmTg4gFe+jyfu+MU9ZOPT8xlrjoXsBFh+J1QYM4b+cFVvBgR48OTKPRfdZ56YUcDvzFuM/1ur7q/ZGv2Z3w3Ey9WBxz7fQ1nFxT0QEzMKmGz3i3EA03dPAkaL6KXJYZRXVvGXRnQRJWUWMMNuPWx8Hdb/CwBHOzP/nhzGybwSXmrE2oKkzAJuM68zxuO2vg2Ah5M9/7x+EAfT8lnQxAHu5mK1RKCUMgNvAROAAcBMpdSAs247DIzWWocB/wQWWCsecR7uXeD2r6FzD1g8HRLWARDo6czn940kyMuZOz/czk8Hm2f+d2uXnldKkMpCdRlorL04ddh4KFYa7wiv6OvHn8f15avdJ5i3/sLvuhMzCqis0oQWxUFghJEMPpsFZUY//sNX92ZIsCdPrtzL4azCBsWYVVBGTlE5PcsOgncvyDsBX8yBqiqUUjx/4yC83Rx45LOGdzvlFhkzXHqXx4OrHxyPhR+eAcDBzsQr08PJK67grxex0KywtILjp4vpU5kA9i4Q/52x3Qng5erACzcO5sDJPN78ObFB9YGRWI/lFNG3MhGUGXZ8XLN9SqiPK4+N7cuPBzMuanZOaUUlKaeK6FtVHccvr8CRjQAM7+bFnaO688nmo2w73PCu0vLKKo5mF9FXV/8f+eEZSDdafmMH+nPtYH9e/zGhVazqt2aLIApI1Fona63LgKXA9bVv0Fpv0lqf6XfYAgRZMR5xPm6+cPtX4NPHSAaxHwPGjJmls0fSp4s7sz+JbZaFVa1del4J3UyZmLxCIfQSuO4VY+3Fmsdq3s3eP7onNwzpyn/WHuL7fWnnre/AyTx8ycGlKBUG3gg3vQdpcfD1o6A19mYT/505FHuzibs/2t6gFd4J6fm4UYRn4WEYPA3GPW88ZDe+ChjdTq9MG0JyZgF/XLarQauOEzLycaQM78IEGHbbb9OMD3wNGDOe/ji2D9/GpfHhxiMXrA+q+8ipwLcwHiLvhr7XGmtYTuwE4JoBXbhpaCBv/ZzIluTsBtWZnFmISVfSpai6zsDh8NUf4PQxAO68pDvDQjx55sv9DV5XcTS7CF1ViX/hIRg6Czp3h5Wza1pZj43rQ5CXM3NX7GlwYj2aXURlVSUBRYdgwA3g5Akr7q3ZCfiZSQNxsjPx5Iq9Vtkv6mJYMxEEAsdqfZ5afe1c7ga+tVSglJqtlIpRSsVkZnbMmSwtwtXb6CbqMcb4xfrhWaiqorOrA4vvHcHwbl48vHQXr6yLt8rmaa3FqdO5+JIDXt2MC8Nug0sfhdgP4ecXAGOw98XJYYQHdeKRz3bVTA+15MDJfKLtq98VBo8wNgIc8yTsWQpb5hmXO/+2wvuBxbEX7DuOT88nzJSMQkPQcIiaDYMmw0/P1XTvXdLLh6eu7c/afem8/mPCBX/uhIwCBqojmHSl8XAd+0/oOtTYo6q6K2v2ZT0YO6ALz6850KDVvAnpBfRTKZiqyo06r38L3Pzg8zuhxHjNnrl+IN28XXhw0Q5OnL7wXkQJGfn0UamYK0sgKAomv2/0v6+8FyorMJsUL08bQlWV5v6FOygpv/BYTmJGAT3VCewqi43ZdJPfg4K0mmTt4mDHf6aEczS7sMEn/CVlFtBdpWFfUQi9r4Eb5kHGPvjpn4CxC/DT1w1g25FTvNGAfx9rsmYiUBauWXz1lFJXYCSCuZbKtdYLtNYRWusIX1/fZgxR1OPkATd/BsNuh19fgZX3QFkR7k72fHJ3FFOHB/HGjwk8tKQdn2WQW/3+xbPbb9eu+jsMvRU2vARbjK4NJ3sz79wagbuTHbd/sO2c3ToH0/K40u0wmB0hIMy4ePmfod91xsFBe5cDxgrvF24czMbEbJ796vwrUA+lFzDS8bDxSeBwUAp+94bRovvstpouiLsv7c6U4UG8/mPCBdeGxKfnE2Vf3WcdOMzYo2rqR8bnS2ZCSS4mk+KV6UPo4ePKQ4t3XHCaakJGAcPsqpNg12Hg0tl4cJ9OMcYLqirxcLJnwa0RlFZUcf/C2As+uJMyCgg31Yqzc3e47lVI2Qw/PwdAdx9XXpk+hL3Hc/nb6gt3ZSVlFBCmquvsOtR4Tcc8Cfu+gJ2fAjCypzd/GtuXr/ecbFCLKCmzgMG16+x9DUTeC5vfNFqYGGeJTx4WxBs/JbC+kTOTmoM1E0EqEFzr8yCg3miYUioMeA+4XmvdsLahsC6zPfzudbj6GYhbCe9fA9lJONqZeWlKGE9d249v49KY+s4mUrKbb4fK1sIhvzoReNVKBErBda8ZD+/v5sKezwFj8PjTu0dQUaW55d0t9R6MWmsOnMxjmEowHgZ2jkaByWQ8ELtdYvTtJ/4IwNSIYO4b3YOFW1J475fD54wxIT2faIfDxviAs5dx0dENbvkcHFxg4RTITa0ZLxgW4smflu0+7+BxQnoBo5yOgEeQMYkAwCsUpn8CWfHw2a1QUYabox3v3hZBZZXm3k9iKCo7d1dJYkYBlzilgIuPMSEBoNtIGPcCHPy6ZquTXn5uvDwtnN2pF35wJ2YWMMo5xZj11rmHcTFsKgy/A359FXYuAoxup99faQzEL9l27Jz1nalzpHOKcZCTdy/j4qWPQvfR8PUfa6ZX3z+6J1f378ILaw4Qc+T84wVJGYVEOx0DO2fw6WtcvOYfxpTtz++E7CSUUjx3wyD6dnHnkc92NcsWIY1hzUSwHeitlOqulHIAZgBf1r5BKRUCrARu1Vq3rhUWHZ1Sxi/CLcsh7zi8Mxr2r0YpxezLe/LebREczS5i4hu/tKvzDCoqq+hUUv3z1G4RAJjtjId36GWwak7NO/k+Xdz59O4oCkoruPm9LXW2Ws7IL6WoqJCg4kPGXk+12TvBzCXg2894yKbGAvD4uH5cO9if59cc4P1f6ycDY8ZQHv0q443B59o8Q4x/s7ICY0pwcQ6Odmbm3zocLxd7bv9g2zmPKE3IyGeATjTeZdfWYwxMehMO/w++/D1oTaiPK2/MHEp8ej4PLd55zlk/iRn5DFJJRp2qVidB9JzfxiC2vQvAuIH+NQ/u873jTjzTIug6tG6d1/5fdbfmwzVToR+5ug+X9/Hl71/GnXcTucSMAoaYD0NAuLHgEow/p31svCFYegucSq5ZqxHk5cwDi3aQkX/uaapJmQUMtTsM/oON/ztgJOmZi0GZamajOTuYeXvWcCorNQ8u2tEseyZdLKslAq11BfAQsBY4ACzTWu9TSs1RSs2pvu1vgDcwTym1SykVY614RCP1vhru+wV8+xhTFNf8GcoKuap/F9b84TJ6dXHjocU7eXLlnnbRVZRVUEagyqDS5ABuXerfYO8EMxYbff0r7oGYDwEY2LUTn949gpzCcm5+d2tNy+DAyTwGqiOYdbnxNWdz6gSzVhiD9YumwImdNesVJgzy559f7+e9X+pOMUzPK8W9JA33ilMQFFG/Tv9Bxmyn7CSjS6e0AD93JxbdG43ZpLj53S0knJUMcovLKcvLxKf8hOU6h8yEK/5qjGv8ZHS/jOnrxz9vGMRPBzN4cPGOeuMaJeWVZJ/KJqDsqNHVcrbx/4I+E+Dbx+HQd4Dx4B43sAv/+Ho/S7al1PuSisoqjmflEFRenQhqM9vD1I+NVsJnsyArAbNJ8caMIQR0cuauj7az/0T9sZyqKk1KZi7dypPq1+nsBTcvM2Z6LTYe3J2c7Xl71nDySsq566Pt5BbXH9zXWnM4I4/uFRbq7NwDpn8Kp5JrZqN193HlP1PD2J2ay5Mr9rb4GJxV1xForddorftorXtqrZ+vvjZfaz2/+u/3aK29tNZDqj8s/A8UNucZDHd+B9EPwrYFMP9SSNlCcGcXlt03svqks2Nc+8YvbG3gzI/WKj2vhCCVSYlroNF9Y4mTh/Hw7n0NfP0IbHwDgPBgTz6+K5LsglJunLeJPamnOXAyn+Gm6sbu2S2CM9y7wK1fGN0SH10HhzfUnBUxcXAAz31zoM6GavHp+QwxVfe7W3rAAvQYDTe9A8e2wqc3QHEO3X1cWTI7GqUUM9/dWmf308SM/Fr97ueo8/LHjLGjX/4Pfv4XaM0tI7rx7KSBrNufzh+W1D3EJzmzkAEcMQa0uw6rX5/JDFPeB/8w44GY/D/jwT1zKFf09eWpL/ay/KztPFJOFdGr6ihmXWm5TmdPuGUZmOyMdTG5x/F0cWDRPSNwcTBz6/tb6yXBE7nFBFWkYK/L6j+0Abx7Vk8jToLP74AKYwO9t28ZzqG0fO78cFu9mUSZ+aX4lB3DsaoYug6pX2fopca4RtJPxjiR1owfFMBjY/uwcudxnm7AuEZzkpXFomHsHGD8C8Z6g6oK+GA8rP0L9pXFzB3fj8X3jKCiqorpC7bwly/2kt/IfWlsLT2vhGCVSVWnkPPfaO8M0xfBwJtg3dOw9i9QWcHwbp1Zcf8oHO1MTH9nC1/sTOUSxyTw6m7MljmXzj3g7rXQKdjo0tn/JfZmE6/NGMLEsACeX3OAZ7/aR0VlVXUiSESbHaHLoHPXOWiy8Q755G74cCLkp9PT140l9xotkxkLttTscxSfXkC4SkIrEwRYeHBB9TjJqzBkFvzvxZoH2O2jQvnrxP58G5fGI5/tqukmSsjIJ9xUPS//7O6mMxxcjXENr1DjwR2/Fkc7o6vkkp4+PL58d50pywkZBYTVHii2xCsUZi6Fwiz4cALkHCW4swuL7hmByaS45b2tHKk1sJ+YUcBgU61BXUu6X2YMxif/DEtvhvJirujnx39nDmV3ai53f7y9ziB3YuZZg8+WDLsNRj4E294xzhTXmgev6MWc0T1ZtDWFF9YcaLFkIIlAXJzul8H9m4yBuc1vwpuRsO8LRvX0Zu0jl3PPpd1Zsi2Fa17ZwOpdx1vl3uvncyYRmL1DL3yznYMxzfDMTJCFN0FhNr27uPPFg6Po3cWN+PR8hhJvuVvobB5d4c41xoP489th6wLsTYrXpw+p2SL8zo+2E3s0h0i7ZFRAuBHD+QyYZHRt5ByBD8bBqcP08nNn6ewRONmbmDp/M1/tPkFCegHD7JKN8QpHt3PXZzLDpP8a52BvmWeMGVRVcs9lPXhyQj++2XOSWe9v5VRhWc3sHt0pBFx9zl2nm58xbdmvv9EXv28VTvZm3r0tgojQzjz62S4++PUwWuua8YEqVz/wOM9s9OBIuG01lJw2kkF2Ej183arfsGhmvrul5nyJpMxCwlUyVY4evw0+WzL0FuNnT/wRFk+DskLGDwrglWnhbD18itmfxtYMnCdlFhJmSqbKztmYyXUu1/wTIu42VjN/9yQKmDu+L3eMCuXdXw7z6g8JLfI7JIlAXDxHd/jda0Z3kXNno7n8yfW45MTz1+sGsOL+Ufi4O/Dw0l3c9PamNrVXUc6pbLxUAU4+53kg1GYyw8T/M+bHp2yBBaPhxE783J1YOjuaP0U60qkq59zdQmdz6Qy3rYLe4+DbP8OKe7CrKOJvvxvAvycPZktyNuviUhlAsuW+fEt6XmE8FItz4N0rIGEdvfzcWfXgJQwO7MTvl+xkRewxhpqSUOd6l13nZzbB+Bfh8seNqZVLZkJxDveN7snrM4aw69hpbnhrI/9LyGKY3eGG1enSGW7/0uiWWn4nbH8fZ3sTH90ZydX9jTGDp76I42BaPsPsDmM6e/DZkqDhRoKpKDWSQVocvbu4s/DuEVRpzeR5m/jxQDqJGcagrunswWdLht0GN74DR36FT2+CkjyuHxLIv28K49eETKa8vZmTucVGEjQfMZL1mcHnc72WE1+GEfcbW1B88yeU1vztugFMizCmaj/1RZzV9ySSRCAar9tImL3emK1xche8PQpW3sdQ91y+fPBSXpoSRmpOMTfN28SDi3fU65ttjSpOHQHA1Lnb+W8829BZcNd3xsrj98fCr6/iYobf96qeYtiQFsEZDq7GgPRVf4N9K+HdKyHjINMjQ1h0TzTRbuk4UHbuvnxLgiPh3p+Md9GLpsJPz+PjYseie0cwZXgQHqXH8dB5Da9TKbjyL8a/fdKPsGAMnNzD9UMC+Wx2NEVllRw7lkKAzmh4nU6d4NaV0PMq+OaPsPpBXFQ582cNrx6HSuHH3cmE6tRzd7eczX+w0cpSJmMa9N7lDOjqweoHL6WHrxv3fBLDD3tT6E1Kw+sMnw5TPoDjMfDe1ZCVwLTIYN6/I5KUU0VMenMjmxLSGaCOoBpSp1LGwPklD0PM+7DiLkzlhbx4UxgPVP/ct3+wjdNFTT8p7lwkEYimMdtB1L3wh10w6vewfxX8NwLTmj8xrZfm58fG8NAVvVh/MIOxr23g90t21uxP3xqZcqtnqnheYIzAksBhcN//oM84Y1+Z96+BuBXg4G50e1xUICa47E9w6yooPmU8aDf9l6gQDz4dW/1r29AWwRnePeHudRA+01gYt/AmHAtO8J8pYbx5eXX3w8UkFzD+7e/81tic7v1rYMenDA325MuHLuHWkOqVxw1pEZzh4GosaLz8cdi1CN6/BtPpI8wd34+Xp4YzxO4opnMNPp+Lb1/jDUtAuHFe97dP4O9mZtl9I41jKUuSsafi4uIceCPMWglFWbDgCjjwFVf09asZHyIrHidKG55clIKrnzU+9q+G967GlJPM49U/9/Yjp7hx3iaSrbQvkSQC0TxcOhtbEvxhFwy71dgI7PUhuH3zAI8NqeCXuVcyZ3RPfjyQzjWvbuCej2PYkpzd6sYQnAqqZ6l4hjauAlcfmPYpTPkQTh+FhLXGA/t83QPn02O0MX23x2hjB8v3rkLtX1W9QOsiWy1gzGO/YZ6xYPDYNpgXjdq2gHDijYVPfmfvC9kAwVFw3wbjzy8fgsXT6EoWjw4oBJTxAL4YJrPR2rh5mbEC+Z3REPsRk4d25d2rqrtuLuahDcYCudu/+q0L5qOJOOcf4c2Zw/hHZPU77YY+tM/oMdr4uX37GNNV1/2Nvj4OrHrwEu4IrT5rwNKMoXNRCi59xEgwBelG8j/4DZOHB7H43mhyi8tZvLX+lNrmoFrbL+KFRERE6JgYWW7Q6uWmwuZ5EPsRlBdCzysh4m6yA6/g4y2pLNyawqnCMgYFenD7yFCuC+uKs0MjH5bNaPEzM5hsWo/j0ycv3F98IYVZ8L9/G/39va9uWl1aG9sdfDsXCjOM+fc3L21anTlHjFWzST8Cyui+untt4+urqoSt79SsM8DF23iH/+CWxtd56jCsfgiO/mqswkYZyeHRvY2vc+9y4+euKIHRj0NWAiSugz8nNe7fvKLU+HeJ/dBYQfy7140uvV2L4YmUxr0JOJ1iLDI8uQvCZsC45zle7oqfuyP25sa9f1dKxZ5rir4kAmFdRaeMfs+YD40Vyh6BMOx2SgZN54tkE+//epjEjALcHe24fmhXZkSGMLCrB6qpD+FGKCmv5Jd/XM1Qjzx8/hzb4t+/QYpzjHULva+BbqOaXp/WsGeZ0dqInmN0RzXV6RTjQZu4zhg7uf6tptVXVWUMSq97Gkpyof8kY0FWU+SnGQvZ9q82Pu91tbE2pCkS1hk/d26K0R0YEGaMTzRWeQn88rKxbYaju7EtR/iMRr9BkUQgbK+ywtgmOeb9mg236HYpOnw6sS6XsWh3Lmv2nqS0oorefm5MCu/KpCFd6ebt2mIhHjtVROFrUbgH9CLw/lUt9n1bDa2b3gqqXdfhDcZ0VHcLK7QbIz/d2Aix/yRje/DmcHCNMYd/5IPGlOimKi0wDrXZMs9Iqlf+tel1Zhwwts04ttVY1Dn+hUZVI4lAtC45R413oXuWQnYimOyhxxiKek3k67KhLN9fzLbqDb0GB3Zi7IAujB3oT58ublZtKWw/nM2Aj/qT028mQTNft9r3ER1AfpqxPcWZTQabqqoKYj+A4GhjC5FGkEQgWietjVOw9q8ymuinU4xpfkFR5AZfwffl4Sw+4s7OY8aOmSGdXRjT15fRfXyJ7uGNq6Nds4bz/fY4xn5zCRmjnsFv7KPNWrcQtna+RNC8v0lCXAyljBk1QRHGCsuTu+HgN5DwPZ02/YupwFRXP0rCL2GXfTgrTvXg85gSPtl8FHuzYliIF9E9vInu4c3QEE+c7Js22FycYWwJ4NKlgYvJhGgnJBGI1kEpY6pd1yHG1MH8NEj8AZLX43R4A9EFXxANvOQZQHbnoezQ/fg2N4T5P3Xm9R/tcDCbGBTowfBuXgwL8WJIiCf+Hk4X1ZVUdeooAK6SCEQHI4lAtE7u/saMk6GzjC6kzENw5BdUyhZ8UrYwNm8NY4FXXBzI69SPBLs+bCsJ4vvNXfj4l66UYY+PmyNhQZ0YFNiJAQEeDAjwILiz8zmTgznPmKOtvEJb7ucUohWQRCBaP6XAr5/xEXWvce30MTgeizoeS6fjO4g4+R0RZQU8YAfa3o7TrqEcMYWw+2QAWxL8+KaqK0d1F5wdnejdxY3efu7Gn13c6eHjSqCnM86FqeQpDzwc3W378wrRwiQRiLbJM9j4GHiD8XlVFeQchrQ9qJN78Mo4gFfGfoaW/sQd9tW3KDuyHbpyNDeAg5m+HNzpywbtR4r2I9Psx3xTKjnO/njY7qcSwiYkEYj2wWQy9tLx7mnsA3NGaYHRrZSdgCkrHt+seHyzk4k4tQfsfztSUqPQKLL8xtogeCFsSxKBaN8c3YztiIPO2kxNa2NA+lQynD6KyjmKyk3FL3yGbeIUwoYkEYiOSSnwCDA+aKZVqkK0UbL7qBBCdHCSCIQQooOzaiJQSo1XSh1SSiUqpZ6wUK6UUm9Ul+9RSl3kJuNCCCGaymqJQCllBt4CJgADgJlKqbNPvZgA9K7+mA28ba14hBBCWGbNFkEUkKi1TtZalwFLgevPuud64BNt2AJ4KqUCrBiTEEKIs1gzEQQCx2p9nlp97WLvQSk1WykVo5SKyczMbPZAhRCiI7NmIrC0ocvZe1435B601gu01hFa6whfX99mCU4IIYTBmokgFQiu9XkQcKIR9wghhLAiqx1MqWyZpQAABZBJREFUo5SyA+KBq4DjwHbgZq31vlr3TAQeAq4FRgBvaK2jLlBvJnC0kWH5AFmN/Nr2TF4Xy+R1sUxeF8ta++vSTWttsUvFaiuLtdYVSqmHgLWAGfhAa71PKTWnunw+sAYjCSQCRcCdDai30X1DSqmYc53Q05HJ62KZvC6WyetiWVt+Xay6xYTWeg3Gw772tfm1/q6BB60ZgxBCiPOTlcVCCNHBdbREsMDWAbRS8rpYJq+LZfK6WNZmXxerDRYLIYRoGzpai0AIIcRZJBEIIUQH12ESwYV2Qu0olFLBSqmflVIHlFL7lFIPV1/vrJRap5RKqP7Ty9axtjSllFkptVMp9XX15x3+NQFQSnkqpZYrpQ5W/78ZKa8NKKUerf4dilNKLVFKObXV16VDJIIG7oTaUVQAf9Ja9weigQerX4sngB+11r2B/2/v3kKsquI4jn9/aVetHuwCKTEGVpCQRkYXi0jpoaQiCKMkIaILlPUQYr31EARG1FMQRQVZEGnlkwqFWUYm2jRC0ktFGd7AMjXoYr8e1ho66mhTjG6H9fu8nH05e591/pwz/9lrnf1fH9T11jwKbO5ZT0yKF4AVti8GLqXEqOnYSJoILAAutz2Vcq/UnYzSuDSRCBheJdQm2N5qe2Nd3kP5Uk+kxOP1+rTXgdu6aWE3JE0CbgZe7tncdEwAJJ0BXAe8AmD7d9s/k9hAuQ/r1FpF4TRKeZxRGZdWEsGwqpy2RlIfMB1YB5xreyuUZAGc013LOvE8sBD4q2db6zEBuADYCbxau81eljSOxmNj+0fgWeB7YCuw2/YqRmlcWkkEw6py2hJJ44GlwGO2f+m6PV2SNAfYYXtD1205Do0FLgNetD0d2Mco6e44mmrf/63AZOA8YJyked226v9rJRGkymkPSSdSksAS28vq5u2DkwLVxx1dta8D1wC3SPqO0m14g6Q3aDsmg7YAW2yvq+vvUBJD67GZDXxre6ftP4BlwNWM0ri0kgjWA1MkTZZ0EmVQZ3nHbeqEJFH6ezfbfq5n13Jgfl2eD7x/rNvWFdtP2J5ku4/y2fjQ9jwajskg29uAHyRdVDfNAr4isfkeuFLSafU7NYsy3jYq49LMncWSbqL0Aw9WQn264yZ1QtJM4GNgE//0hz9JGSd4Gzif8iG/w/auThrZIUnXA4/bniNpAokJkqZRBtFPAr6hVAk+gcZjI+kpYC7ll3hfAPcB4xmFcWkmEURExNBa6RqKiIjDSCKIiGhcEkFEROOSCCIiGpdEEBHRuCSCaJakT+tjn6S7RvjcTw71WhHHo/x8NJrXe+/AfzhmjO39R9i/1/b4kWhfxNGWK4JolqS9dfEZ4FpJ/bXG/BhJiyWtlzQg6YH6/OvrXA5vUm7IQ9J7kjbUuvT3123PUKpS9kta0vtaKhbXGvabJM3tOffqnrr/S+odqxFH3diuGxBxHFhEzxVB/YO+2/YMSScDayWtqs+9Aphq+9u6fq/tXZJOBdZLWmp7kaSHbU8b4rVuB6ZR6vqfVY9ZU/dNBy6h1MFaS6mB9MnIv92IA+WKIOJQNwL3SOqnlN6YAEyp+z7vSQIACyR9CXxGKWw4hSObCbxle7/t7cBHwIyec2+x/RfQD/SNyLuJ+Be5Iog4lIBHbK88YGMZS9h30Pps4Crbv0paDZwyjHMfzm89y/vJ9zOOkVwRRMAe4PSe9ZXAQ7VcN5IurJOxHOxM4KeaBC6mTP056I/B4w+yBphbxyHOpsz+9fmIvIuI/yn/cUTAAPBn7eJ5jTJHbx+wsQ7Y7mToKQdXAA9KGgC+pnQPDXoJGJC00fbdPdvfBa4CvqRMjrTQ9raaSCI6kZ+PRkQ0Ll1DERGNSyKIiGhcEkFEROOSCCIiGpdEEBHRuCSCiIjGJRFERDTubx14M6gaH9+/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot('loss','all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1782,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:45:22.876062Z",
     "start_time": "2020-05-09T05:45:19.875876Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74037455c63c41ffaede5deacc2efb6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EPOCH :', layout=Layout(flex='2'), max=6.0, style=Progres‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/6] - train :: accuracy: 1.0000 | loss: 0.2785 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.2219 \n",
      "        epoch time: 00 s 568 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/6] - train :: accuracy: 1.0000 | loss: 0.2385 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.1882 \n",
      "        epoch time: 00 s 552 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/6] - train :: accuracy: 1.0000 | loss: 0.2017 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.1599 \n",
      "        epoch time: 00 s 445 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/6] - train :: accuracy: 1.0000 | loss: 0.1710 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.1369 \n",
      "        epoch time: 00 s 576 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/6] - train :: accuracy: 1.0000 | loss: 0.1462 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.1183 \n",
      "        epoch time: 00 s 416 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/6] - train :: accuracy: 1.0000 | loss: 0.1263 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.1033 \n",
      "        epoch time: 00 s 370 ms\n",
      "\n",
      "-----\n",
      "total time: 02 s 993 ms\n",
      "best score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:29:59.131407Z",
     "start_time": "2020-05-09T05:29:59.126328Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 1754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.M.phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T16:39:41.429869Z",
     "start_time": "2020-05-08T16:39:35.503681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceea2bea51d4316a48ae3d68fc0b027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EPOCH :', layout=Layout(flex='2'), max=2.0, style=Progres‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=130.0), HTML(value='')), layout=Layout(di‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] - train :: loss: 1.3984 | accu: 0.2428 \n",
      "        valid :: loss: 1.3488 | accu: 0.3719 \n",
      "        epoch time: 02 s 996 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=130.0), HTML(value='')), layout=Layout(di‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] - train :: loss: 1.3490 | accu: 0.3881 \n",
      "        valid :: loss: 1.2926 | accu: 0.6198 \n",
      "        epoch time: 02 s 891 ms\n",
      "\n",
      "-----\n",
      "total time: 05 s 922 ms\n",
      "best score: 0.6198\n"
     ]
    }
   ],
   "source": [
    "# trainer.fit(epochs=3, train_dl=dl[TR], valid_dl=dl[VA])\n",
    "trainer.fit(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T05:28:16.611769Z",
     "start_time": "2020-05-09T05:28:16.418958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aafd224421f4390bb77285fed4ef3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5.0), HTML(value='')), layout=Layout(disp‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test :: accuracy: 0.3478 | loss: 1.3875 \n",
      "\n",
      "-----\n",
      "total time: 00 s 182 ms\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T03:06:05.594054Z",
     "start_time": "2020-05-09T03:06:04.944129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING SANITY CHECK: TRAIN LOOP - 1 EPOCH(s), None STEP(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c8f8fa3fbe4e49892a255ef1251fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EPOCH :', layout=Layout(flex='2'), max=1.0, style=Progres‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1] - train :: accuracy: 0.9615 | loss: 0.8845 \n",
      "        valid :: accuracy: 1.0000 | loss: 0.7679 \n",
      "        epoch time: 00 s 435 ms\n",
      "\n",
      "-----\n",
      "total time: 00 s 467 ms\n",
      "best score: 1.0000\n",
      "\n",
      "RUNNING SANITY CHECK: TEST LOOP - None STEP(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d18a3352de463a981bdd7a2cd6140f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5.0), HTML(value='')), layout=Layout(disp‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test :: accuracy: 0.9565 | loss: 0.8922 \n",
      "\n",
      "-----\n",
      "total time: 00 s 175 ms\n"
     ]
    }
   ],
   "source": [
    "# trainer.run_sanity_check(use_test_dl=True,steps=None, train_dl=dl[TR], valid_dl=dl[VA], test_dl=dl[TE])\n",
    "trainer.run_sanity_check(use_test_dl=True,steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1527,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-09T03:07:07.704034Z",
     "start_time": "2020-05-09T03:07:07.077814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING PROFILER: TRAIN LOOP 1 EPOCH(s)\n",
      "  train dl :: batches:   11 batch_size:    5 last_batch:    2 dataset_size:     52\n",
      "  valid dl :: batches:    3 batch_size:    5 last_batch:    2 dataset_size:     12\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9465ea28e4f94399abf847af7ce89252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='EPOCH :', layout=Layout(flex='2'), max=1.0, style=Progres‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=14.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RUNNING PROFILER: TEST LOOP \n",
      "  test  dl :: batches:    5 batch_size:    5 last_batch:    3 dataset_size:     23\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b3bd4826d5409689c6763d40b02178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5.0), HTML(value='')), layout=Layout(disp‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AVERAGE TIMES\n",
      "1. initialize:       00 s 002 ms 376 us\n",
      "2. train\n",
      "  1. epoch_start:    00 s 195 ms 899 us\n",
      "  2. step:           00 s 002 ms 212 us\n",
      "  3. batch_inner:    00 s 002 ms 683 us\n",
      "  4. batch_loop:     00 s 309 ms 984 us\n",
      "  5. epoch_end:      00 s 226 ms 800 us\n",
      "  6. phase_inner:    00 s 310 ms 140 us\n",
      "3. valid\n",
      "  1. epoch_start:    00 s 785 ms 004 us\n",
      "  2. step:           00 s 000 ms 549 us\n",
      "  3. batch_inner:    00 s 001 ms 121 us\n",
      "  4. batch_loop:     00 s 059 ms 311 us\n",
      "  5. epoch_end:      00 s 020 ms 299 us\n",
      "  6. phase_inner:    00 s 059 ms 455 us\n",
      "4. phase loop:       00 s 398 ms 314 us\n",
      "5. epoch\n",
      "  1. inner:          00 s 400 ms 646 us\n",
      "  2. loop:           00 s 429 ms 772 us\n",
      "  3. inner_t:        00 s 170 ms 788 us\n",
      "  4. loop_t:         00 s 170 ms 992 us\n",
      "6. restore model:    00 s 001 ms 514 us\n",
      "7. total:            00 s 433 ms 714 us\n",
      "8. initialize_t:     00 s 000 ms 940 us\n",
      "9. test\n",
      "  1. epoch_start_t:  00 s 181 ms 996 us\n",
      "  2. step_t:         00 s 001 ms 010 us\n",
      "  3. batch_inner_t:  00 s 001 ms 496 us\n",
      "  4. batch_loop_t:   00 s 122 ms 710 us\n",
      "  5. epoch_end_t:    00 s 256 ms 299 us\n",
      "  6. phase_inner_t:  00 s 122 ms 870 us\n",
      "10. phase loop_t:    00 s 158 ms 051 us\n",
      "11. restore model_t: 00 s 001 ms 167 us\n",
      "12. total_t:         00 s 173 ms 154 us\n",
      "\n",
      "total time: 00 s 611 ms 082 us\n"
     ]
    }
   ],
   "source": [
    "# _ = trainer.run_profiler(epochs=2, steps=None, train_dl=dl[TR], valid_dl=dl[VA], test_dl=dl[TE])\n",
    "_ = trainer.run_profiler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### FitLoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Bare minimum to structure and push to Pypi:\n",
    "    - Test on console.\n",
    "    - Metrics plot\n",
    "    - Onchanging model update parameters appropriately\n",
    "    - ‚úÖMetrics Viz\n",
    "    - ‚úÖFitLoopDefaults (really simple ones)\n",
    "    - ‚úÖAll stage functions except for `train_step` should be optional that's the only one that is required for training the model, rest all are for metric keeping.\n",
    "    - ‚úÖMake it easy to train, validate, test with some other DataLoader that is not attached to the object.\n",
    "    - ‚úÖFix No Continue\n",
    "    - ‚úÖMetrics\n",
    "- `FitLoop.save(path:str)` to save the model and training state somehow even the FitLoop state.\n",
    "- `FitLoop.load(path:str)` to load the FitLoop state from given path.\n",
    "- ‚úÖ`FitLoop.profiler()` mode to capture all stage timings and maybe even CPU, GPU, RAM usage to check for bottlenecks and usage spikes, to be used with timed_test.\n",
    "- ‚úÖif `FitLoop.fit(define_all:bool=False)` the zero_grad and the context manager are not auto set.\n",
    "- ‚úÖshould keep track of epochs that have been completed\n",
    "- ‚úÖepoch_number can be reset \n",
    "- ‚úÖ`FitLoop.metrics.set_name.loop_stage['metric_name']` to access the metric\n",
    "- ‚úÖ`FitLoop.store_pretrained:bool` arg to store the pretrained weights before training\n",
    "    if path then store at given path else store in memory.\n",
    "- ‚úÖ`FitLoop.reset(reset_model:bool)` to clear metrics, epoch_num and to reset the model, to pretrained state\n",
    "    will load the weight from passed path else from memory.\n",
    "- ‚úÖ`FitLoop.fit(continue_loop:int=0)` ask after `int` whether to continue training or to end.\n",
    "- ‚úÖ`FitLoop.fit(profiler:bool=False)` mode to capture all stage timings and maybe even CPU, GPU, RAM usage to check for bottlenecks and usage spikes, to be used with timed_test.\n",
    "- ‚úÖFunctionality to view the metrics.\n",
    "- ‚úÖModel score should be a loop instance so that the best model may not be erased.\n",
    "- ‚úÖTime keeping/ metric keeping:\n",
    "    - General\n",
    "        - ‚úÖMetrics returned in the batch step\n",
    "        - ‚úÖMetrics returned in the end step\n",
    "        - ‚úÖProgress bar for epoch\n",
    "        - ‚úÖProgress bar for batch that disappears after complete\n",
    "        - ‚úÖEpoch timing (for both phases when training)\n",
    "        - ‚úÖTotal timing \n",
    "        \n",
    "    - Profiler Mode:\n",
    "        - ‚úÖIndividual Stage Timings\n",
    "        \n",
    "- ‚úÖCheck with uneven batchsizes.\n",
    " \n",
    "#### Later Incremental Addons\n",
    "- Profiler Mode:\n",
    "    - Use an actual profiler ie: `cProfile`\n",
    "    - Individual Stage CPU Usage\n",
    "    - Individual Stage GPU Usage\n",
    "    - Individual Stage RAM Usage\n",
    "- Use better logging (maybe) `warnings` and `logging`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ‚úÖFitLoopDefaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- ‚úÖBasic functions for\n",
    "    - ‚úÖtrain_step\n",
    "    - ‚úÖvalid_step\n",
    "    - ‚úÖtest_step\n",
    "- ‚úÖBasic funtions for \n",
    "    - ‚úÖtrain_epoch_end\n",
    "    - ‚úÖvalid_epoch_end\n",
    "    - ‚úÖtest_epoch_end\n",
    "\n",
    "*FitLoopDefaults shouldn't be a class, it should be a module.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ‚úÖMetrics/MetricsAggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "# Value access\n",
    "Fitloop.metrics.train['loss']                 # ‚úÖreturns all losses from epoch end\n",
    "Fitloop.metrics.train.epoch_end['loss']       # ‚úÖreturns all losses from epoch end\n",
    "Fitloop.metrics.train.epoch_start['loss']     # ‚úÖreturns all losses from epoch start\n",
    "Fitloop.metrics.train.batch_step['loss']      # ‚úÖreturns all losses from batch step\n",
    " \n",
    "Fitloop.metrics.train['loss'][0]              # ‚úÖreturns losses for run 0 from epoch end\n",
    "Fitloop.metrics.valid.batch_step['accu'][3]   # ‚úÖreturns all validation accuracies for batch step from run 3\n",
    " \n",
    "# Value visualization \n",
    "Fitloop.metrics.plot()                        # ‚úÖplots validation criteria against training criteria (eg accuracy)\n",
    "                                              # ‚úÖif criteria not available, then first key from rdict.\n",
    "Fitloop.metrics.train.plot()                  # ‚úÖif loss then loss else, plots first value from rdict\n",
    "Fitloop.metrics.train.plot('loss')            # ‚úÖplots loss \n",
    "```\n",
    "- ‚úÖmetrics can be cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ‚úÖLoopState "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- ‚úÖshould cast the batch to device before passing it using `state.batch()`\n",
    "- ‚úÖshould get the batch num `state.batch_num` and epoch num `state.epoch_num`\n",
    "- ‚úÖthe model, optimizer, loss_function, lr_scheduler should be available\n",
    "    `state.model`, `state.optimizer`, `state.loss_function`, `state.lr_scheduler`\n",
    "- ‚úÖshould return the batch metrics as float tensors using square bracket indexing\n",
    "    `state['loss']` \n",
    "    - every step function hook receives the LoopState object.\n",
    "- ‚úÖThe loop state object should have a copy of all the values returned from the function hook\n",
    "- ‚úÖexample the below returned dict values should be avialable in the LoopState object\n",
    "\n",
    "```python\n",
    "def train_step(state):\n",
    "    X,y = state() # should device cast automatically\n",
    "    y_ = state.model(X)\n",
    "    loss = state.loss_function(y_, y)\n",
    "    \n",
    "    state.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    state.optimizer.step()\n",
    "    state.lr_scheduler.step() \n",
    "    \n",
    "    loss = loss.item()\n",
    "    batch_loss = loss * y.size()\n",
    "    batch_corr = (y_.argmax(dim=0) == y).sum().float().item()\n",
    "    \n",
    "    return {'loss':loss,'batch_loss':batch_loss:'batch_corr'}\n",
    "```\n",
    "- ‚úÖThe LoopState object should be cleared of the above values at the start \n",
    "  of the next epoch.\n",
    "- ‚úÖThe returned values should be available through the FitLoop object\n",
    "  Eg: `FitLoop.metrics.train.batch['loss']`\n",
    "- ‚úÖThe (above statement) returned value should be optionally available by setting the flag \n",
    "  `track_batch_metrics`\n",
    "\n",
    "```python\n",
    "def train_epoch_end(state):\n",
    "    loss = state['loss']\n",
    "    batch_loss = state['batch_loss']\n",
    "    batch_corr = state['batch_corr']\n",
    "    \n",
    "    size = state.size\n",
    "    \n",
    "    epoch_loss = batch_loss.sum().item()/size\n",
    "    epoch_accu = batch_corr.sum().item()/size\n",
    "    \n",
    "    return {\"loss\":epoch_loss,\"accu\":epoch_accu}\n",
    "```\n",
    "\n",
    "- ‚úÖThe returned values should be available through the FitLoop object\n",
    "  Eg: `FitLoop.metrics.train.epoch['loss']`\n",
    "- ‚úÖFor each phase a different LoopState obect is maintained.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
